<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BENULL</title>
  
  <subtitle>tomorrow is another day</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-12-26T18:43:52.594Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>BENULL</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>强化学习简介</title>
    <link href="http://yoursite.com/2020/12/27/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/12/27/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-12-26T18:41:28.000Z</published>
    <updated>2020-12-26T18:43:52.594Z</updated>
    
    <content type="html"><![CDATA[<h1 id="强化学习简介"><a href="#强化学习简介" class="headerlink" title="强化学习简介"></a>强化学习简介</h1><p>强化学习(Reinforcement Learning，RL)是机器学习中的一个领域，是学习做什么（即如何把当前的情景映射成动作）才能使得数值化的收益最大化,学习者不会被告知应该采取什么动作，而是必须自己通过尝试去发现哪些动作会产生最丰厚的收益</p><p>强化学习同机器学习领域中的<strong>有监督学习</strong>和<strong>无监督学习</strong>不同，有监督学习是从外部监督者提供的带标注训练集中进行学习（任务驱动型），无监督学习是一个典型的寻找未标注数据中隐含结构的过程（数据驱动型)</p><p>强化学习是与两者并列的第三种机器学习范式，强化学习带来了一个独有的挑战——<strong>探索</strong>与<strong>利用</strong>之间的折中权衡，智能体必须利用已有的经验来获取收益，同时也要进行探索，使得未来可以获得更好的动作选择空间（即从错误中学习）</p><p><img src="https://img-blog.csdnimg.cn/img_convert/1668acdd0c064f8332bbdcc02b5714bc.png" alt="img"></p><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><p>强化学习的主要角色是 <strong>智能体</strong> 和 <strong>环境</strong>,环境是智能体存在和互动的世界。智能体在每一步的交互中，都会获得对于所处环境状态的观察（有可能只是一部分），然后决定下一步要执行的动作。环境会因为智能体对它的动作而改变，也可能自己改变。</p><p>智能体也会从环境中感知到 <strong>奖励</strong> 信号，一个表明当前状态好坏的数字。智能体的目标是最大化累计奖励，也就是<strong>回报</strong>。强化学习就是智能体通过学习来完成目标的方法。<br><img src="https://img-blog.csdnimg.cn/20201227022859486.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="马尔可夫决策过程-MDP"><a href="#马尔可夫决策过程-MDP" class="headerlink" title="马尔可夫决策过程(MDP)"></a><strong>马尔可夫决策过程(MDP)</strong></h3><blockquote><p>MDP 简单说就是一个智能体（Agent）采取行动（Action）从而改变自己的状态（State）获得奖励（Reward）与环境（Environment）发生交互的循环过程，MDP 的策略完全取决于当前状态（Only present matters），这也是它马尔可夫性质的体现</p></blockquote><p>强化学习任务通常用<strong>马尔可夫决策过程</strong> (Markov Decision Process, MDP)来描述，即</p><p>机器处于环境 <script type="math/tex">E</script> 中, 状态空间为 <script type="math/tex">X,</script> 其中每个状态 <script type="math/tex">x \in X</script> 是机器感知到的环境的描述</p><p>机器能采取的动作构成了动作空间 <script type="math/tex">A</script> ; 若某个动作 <script type="math/tex">a \in A</script> 作用在当前状态 <script type="math/tex">x</script> 上, 则潜在的转移函数 <script type="math/tex">P</script> 将使得环境从当前状态按某种概率转移到另一个状态; 在转移到另一个状态的同时, 环境会根据潜在的“奖赏” (reward)函数 <script type="math/tex">R</script> 反馈给机器一个奖赏</p><p>综合起来, 强化学习任务对应了四元组 <script type="math/tex">E=\langle X, A, P, R\rangle,</script> 其中 <script type="math/tex">P: X \times A \times X \mapsto \mathbb{R}</script> 指定了状态转移概率, <script type="math/tex">R: X \times A \times X \mapsto \mathbb{R}</script> 指定了奖赏; 在有的应用中, 奖赏函数可能仅与状态转移有关, 即 <script type="math/tex">R: X \times X \mapsto \mathbb{R} .</script></p><h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><p>机器要做的是通过在环境中不断地尝试而学得一个“策略” (policy) <script type="math/tex">\pi,</script> 根据这个策略, 在状态 <script type="math/tex">x</script> 下就能得知要执行的动作 <script type="math/tex">a=\pi(x)</script> </p><p>策略有两种表示方法:</p><p>一种是将策略表示为函数 <script type="math/tex">\pi: X \mapsto A,</script> 确定性策略常用这种表示</p><p>另一种是概率表示 <script type="math/tex">\pi: X \times A \mapsto \mathbb{R},</script> 随机性策略常用这种表示</p><p>其中 <script type="math/tex">\pi(x, a)</script> 为状态 <script type="math/tex">x</script> 下选择动作 <script type="math/tex">a</script> 的概率, 这里必须有 <script type="math/tex">\sum_{a} \pi(x, a)=1</script></p><h3 id="确定性策略"><a href="#确定性策略" class="headerlink" title="确定性策略"></a>确定性策略</h3><p>确定性策略，在相同的状态下，其输出的动作是确定的</p><p><strong>优缺点</strong></p><ul><li>能够利用确定性梯度优化策略，所以不需要太多的采样数据，计算效率也很快</li><li>由于每次面对同一状态其输出的动作是唯一的，无法讨论一些其它动作的效果，不具有自学习的能力</li></ul><h3 id="随机性策略"><a href="#随机性策略" class="headerlink" title="随机性策略"></a>随机性策略</h3><p>对于随机策略，对于相同的状态，其输出的状态并不唯一，而是满足一定的概率分布，从而导致即使是处在相同的状态，也可能输出不同的动作</p><p><strong>优缺点</strong></p><ul><li>随机策略将探索和改进集成到一个策略中</li><li>需要采样的数据量较大，学习比较慢</li></ul><h2 id="奖励"><a href="#奖励" class="headerlink" title="奖励"></a>奖励</h2><p>强化学习中，奖励函数<script type="math/tex">R</script>非常重要,它由当前状态、已经执行的行动和下一步的状态共同决定</p><script type="math/tex; mode=display">r_{t}=R\left(s_{t}, a_{t}, s_{t+1}\right)</script><p>长期累积奖励有多种计算方式</p><p>其中<script type="math/tex">T</script>步累计奖赏，指的是在一个固定窗口步数<script type="math/tex">T</script>内获得的累计奖励</p><script type="math/tex; mode=display">R(\tau)=\sum_{t=0}^{T} r_{t}</script><p>另一种叫做<script type="math/tex">\gamma</script>折扣奖励，指的是智能体获得的全部奖励之和，但是奖励会因为获得的时间不同而衰减。这个公式包含衰减率<script type="math/tex">\gamma \in(0,1)</script>：</p><script type="math/tex; mode=display">R(\tau)=\sum_{t=0}^{\infty} \gamma^{t} r_{t}</script><p>这里为什么要加上一个衰减率呢？为什么不直接把所有的奖励加在一起？可以从两个角度来解释： 直观上讲，现在的奖励比外来的奖励要好，所以未来的奖励会衰减；数学角度上，无限多个奖励的和很可能 不收敛，有了衰减率和适当的约束条件，数值才会收敛</p><h2 id="探索与利用"><a href="#探索与利用" class="headerlink" title="探索与利用"></a>探索与利用</h2><blockquote><p>所谓探索：是指做你以前从来没有做过的事情，以期望获得更高的回报</p><p>所谓利用：是指做你当前知道的能产生最大回报的事情</p></blockquote><h3 id="多臂赌博机问题"><a href="#多臂赌博机问题" class="headerlink" title="多臂赌博机问题"></a>多臂赌博机问题</h3><p>单步强化学习任务对应了一个理论模型, 即“ <script type="math/tex">K</script> -摇臂赌博机” ， <script type="math/tex">K</script> -摇臂赌博机有 <script type="math/tex">K</script> 个摇臂, 赌徒在投入一个硬币后可选择按下其中一个摇臂, 每个摇臂以一定的概率吐出硬币, 但这个概率赌徒并不知道。赌徒的目标是通过一定的策略最大化自己的奖赏, 即获得最多的硬币</p><p>仅探索(exploration only): 将所有的尝试机会平均分配给每个摇臂(即轮流按下每个摇臂)，最后以每个摇臂各自的平均吐币概率作为其奖赏期望的近似估计</p><p>仅利用(exploitation-only): 按下目前最优的(即到目前为止平均奖赏最大的)的摇臂，若有多个摇臂同为最优, 则从中随机选取一个.<br><img src="https://img-blog.csdnimg.cn/20201227023447177.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>显然，“仅探索”法能很好地估计每个摇臂的奖赏, 却会失去很多选择最优摇臂的机会;“仅利用”法则相反, 它没有很好地估计摇臂期望奖赏, 很可能经常 选不到最优摇臂. 因此, 这两种方法都难以使最终的累积奖赏最大化.<br>事实上，探索和利用这两者是矛盾的, 因为尝试次数(即总投币数)有限, 加强了一方则会自然削弱另一方, 这就是强化学习所面临的“探索-利用困境” (Exploration Exploitation dilemma)</p><p> 显然, 欲累积奖赏最大, 则必须在探索与利用之间达成较好的折中</p><h3 id="epsilon-贪心法"><a href="#epsilon-贪心法" class="headerlink" title="\epsilon -贪心法"></a><script type="math/tex">\epsilon</script> -贪心法</h3><p><script type="math/tex">\epsilon</script> -贪心法基于一个概率来对探索和利用进行折中: 每次尝试时, 以 <script type="math/tex">\epsilon</script> 的概率进行探索, 即以均匀概率随机选取一个摇臂; 以 <script type="math/tex">1-\epsilon</script> 的概率进行利用, 即选择当前平均奖赏最高的摇臂(若有多个, 则随机选取一个)</p><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>Softmax 算法基于当前已知的摇臂平均奖赏来对探索和利用进行折中</p><p>若各摇臂的平均奖赏相当, 则选取各摇臂的概率也相当; 若某些摇臂的平均奖赏明显高于其他摇臂, 则它们被选取的概率也明显更高.</p><h2 id="强化学习的分类"><a href="#强化学习的分类" class="headerlink" title="强化学习的分类"></a>强化学习的分类</h2><p><img src="https://img-blog.csdnimg.cn/20201227023548880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="有模型学习"><a href="#有模型学习" class="headerlink" title="有模型学习"></a>有模型学习</h3><p>考虑多步强化学习任务, 暂且先假定任务对应的马尔可夫决策过程四元组 <script type="math/tex">E=\langle X, A, P, R\rangle</script> 均为已知, 这样的情形称为“模型已知”，即机器已对环境进行了建模, 能在机器内部模拟出与环境相同或近似的状况。在已知模型的环境中学习称为“有模型学习” (model-based learning)</p><p> 此时, 对于任意状态 <script type="math/tex">x, x^{\prime}</script> 和动作 <script type="math/tex">a,</script> 在 <script type="math/tex">x</script> 状态下执行动作 <script type="math/tex">a</script> 转移到 <script type="math/tex">x^{\prime}</script> 状态的概率 <script type="math/tex">P_{x \rightarrow x^{\prime}}^{a}</script> 是已知的, 该转移所带来的奖赏 <script type="math/tex">R_{x \rightarrow x^{\prime}}^{a}</script> 也是已知的</p><p><strong>优缺点</strong></p><p>有模型学习最大的优势在于智能体能够 <strong>提前考虑来进行规划</strong>，走到每一步的时候，都提前尝试未来可能的选择，然后明确地从这些候选项中进行选择</p><p>最大的缺点就是智能体往往不能获得环境的真实模型。如果智能体想在一个场景下使用模型，那它必须完全从经验中学习，这会带来很多挑战。最大的挑战就是，智能体探索出来的模型和真实模型之间存在误差，而这种误差会导致智能体在学习到的模型中表现很好，但在真实的环境中表现得不好（甚至很差）</p><h3 id="免模型学习"><a href="#免模型学习" class="headerlink" title="免模型学习"></a>免模型学习</h3><p>在现实的强化学习任务中, 环境的转移概率、奖赏函数往往很难得知, 甚至很难知道环境中一共有多少状态</p><p>若学习算法不依赖于环境建模，则称为免模型学习(model-free learning),这比有模型学习困难的多</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>机器学习—周志华</li><li><a href="https://leovan.me/cn/2020/05/introduction-of-reinforcement-learning/" target="_blank" rel="noopener">强化学习简介 (Introduction of Reinforcement Learning)</a></li><li><a href="https://spinningup.readthedocs.io/zh_CN/latest/spinningup/rl_intro.html" target="_blank" rel="noopener">OpenAI SpinningUp</a></li><li><a href="https://blog.csdn.net/xbinworld/article/details/79372777" target="_blank" rel="noopener">强化学习方法（一）：探索-利用困境</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;强化学习简介&quot;&gt;&lt;a href=&quot;#强化学习简介&quot; class=&quot;headerlink&quot; title=&quot;强化学习简介&quot;&gt;&lt;/a&gt;强化学习简介&lt;/h1&gt;&lt;p&gt;强化学习(Reinforcement Learning，RL)是机器学习中的一个领域，是学习做什么（即如何把
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="强化学习" scheme="http://yoursite.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>基于Q-Learning 的FlappyBird AI</title>
    <link href="http://yoursite.com/2020/12/27/%E5%9F%BA%E4%BA%8EQ-Learning%20%E7%9A%84FlappyBird%20AI/"/>
    <id>http://yoursite.com/2020/12/27/%E5%9F%BA%E4%BA%8EQ-Learning%20%E7%9A%84FlappyBird%20AI/</id>
    <published>2020-12-26T18:41:28.000Z</published>
    <updated>2020-12-26T19:59:51.823Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于Q-Learning-的FlappyBird-AI"><a href="#基于Q-Learning-的FlappyBird-AI" class="headerlink" title="基于Q-Learning 的FlappyBird AI"></a>基于Q-Learning 的FlappyBird AI</h1><p>在<a href="https://github.com/willz/birdbot" target="_blank" rel="noopener">birdbot</a>实现的FlappyBird基础上训练AI，这个FlappyBird的实现对游戏进行了简单的封装，可以很方便得到游戏的状态来辅助算法实现。同时可以显示游戏界面方便调试，能够看到算法实现的效果。也可以选择关闭游戏界面以及声音，这样游戏仍然能正常运行，一般用于训练阶段，可以减少CPU的占用</p><p>实现参考的是SarvagyaVaish的<a href="http://sarvagyavaish.github.io/FlappyBirdRL/" target="_blank" rel="noopener">Flappy Bird RL</a></p><h2 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h2><p>Q-Learning是强化学习算法中value-based的算法</p><p>Q即为Q（s,a）就是在某一时刻的 s 状态下(s∈S)，采取 动作a (a∈A)动作能够获得收益的期望，环境会根据agent的动作反馈相应的回报reward，所以算法的主要思想就是将State与Action构建成一张Q-table来存储Q值，然后根据Q值来选取能够获得最大的收益的动作</p><div class="table-container"><table><thead><tr><th>Q-Table</th><th>a1</th><th>a2</th></tr></thead><tbody><tr><td>s1</td><td>q(s1,a1)</td><td>q(s1,a2)</td></tr><tr><td>s2</td><td>q(s2,a1)</td><td>q(s2,a2)</td></tr><tr><td>s3</td><td>q(s3,a1)</td><td>q(s3,a2)</td></tr></tbody></table></div><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p><img src="https://img-blog.csdnimg.cn/2020122703554185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>在更新的过程中，引入了学习速率alpha，控制先前的Q值和新的Q值之间有多少差异被保留</p><p>γ为折扣因子，0&lt;= γ&lt;1，γ=0表示立即回报，γ趋于1表示将来回报，γ决定时间的远近对回报的影响程度</p><p>详细的Q-Learning过程可以参考下面这篇</p><p><a href="https://blog.csdn.net/itplus/article/details/9361915" target="_blank" rel="noopener">A Painless Q-learning Tutorial (一个 Q-learning 算法的简明教程)</a></p><h2 id="FlappyBird中应用"><a href="#FlappyBird中应用" class="headerlink" title="FlappyBird中应用"></a>FlappyBird中应用</h2><h3 id="状态空间"><a href="#状态空间" class="headerlink" title="状态空间"></a>状态空间</h3><ul><li>从下方管子开始算起的垂直距离</li><li>从下一对管子算起的水平距离</li><li>鸟：死或生</li></ul><p><img src="https://img-blog.csdnimg.cn/img_convert/213ef34c9129af22c9bb1af354c6569f.png" alt="img"></p><h3 id="动作"><a href="#动作" class="headerlink" title="动作"></a>动作</h3><p>每一个状态，有两个可能的动作</p><ul><li>点击一下</li><li>啥也不干</li></ul><h3 id="奖励"><a href="#奖励" class="headerlink" title="奖励"></a>奖励</h3><p>奖励的机制完全基于鸟是否存活</p><ul><li><strong>+1</strong>，如果小鸟还活着</li><li><strong>-1000</strong>，如果小鸟死了</li></ul><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p>伪代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">初始化 Q = &#123;&#125;;</span><br><span class="line">while Q 未收敛：</span><br><span class="line">    初始化小鸟的位置S，开始新一轮游戏</span><br><span class="line">    while S != 死亡状态：</span><br><span class="line">        使用策略π，获得动作a=π(S) </span><br><span class="line">        使用动作a进行游戏，获得小鸟的新位置S&apos;,与奖励R(S,a)</span><br><span class="line">        Q[S,A] ← (1-α)*Q[S,A] + α*(R(S,a) + γ* max Q[S&apos;,a]) // 更新Q</span><br><span class="line">        S ← S&apos;</span><br></pre></td></tr></table></figure><ol><li><p>观察Flappy Bird处于什么状态，并执行最大化预期奖励的行动。然后继续运行游戏，接着获得下一个状态s’</p></li><li><p>观察新的状态s’和与之相关的奖励：+1或者-1000</p></li><li><p>根据Q Learning规则更新Q阵列</p><p>Q[s,a] ← Q[s,a] + α (r + γ*V(s’) - Q[s,a])</p></li><li><p>设定当前状态为s’，然后重新来过</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20201227035602587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyglet</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> atexit</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pybird.game <span class="keyword">import</span> Game</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bot</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, game)</span>:</span></span><br><span class="line">        self.game = game</span><br><span class="line">        <span class="comment"># constants</span></span><br><span class="line">        self.WINDOW_HEIGHT = Game.WINDOW_HEIGHT</span><br><span class="line">        self.PIPE_WIDTH = Game.PIPE_WIDTH</span><br><span class="line">        <span class="comment"># this flag is used to make sure at most one tap during</span></span><br><span class="line">        <span class="comment"># every call of run()</span></span><br><span class="line">        self.tapped = <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        self.game.play()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># variables for plan</span></span><br><span class="line">        self.Q = &#123;&#125;</span><br><span class="line">        self.alpha = <span class="number">0.7</span></span><br><span class="line">        self.explore = <span class="number">100</span></span><br><span class="line">        self.pre_s = (<span class="number">9999</span>, <span class="number">9999</span>)</span><br><span class="line">        self.pre_a = <span class="string">'do_nothing'</span></span><br><span class="line"></span><br><span class="line">        self.absolute_path = os.path.split(os.path.realpath(__file__))[<span class="number">0</span>]</span><br><span class="line">        self.memo = self.absolute_path + <span class="string">'/memo'</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> os.path.isfile(self.memo):</span><br><span class="line">            _dict = pickle.load(open(self.memo))</span><br><span class="line">            self.Q = _dict[<span class="string">"Q"</span>]</span><br><span class="line">            self.game.record.iters = _dict.get(<span class="string">"iters"</span>, <span class="number">0</span>)</span><br><span class="line">            self.game.record.best_iter = _dict.get(<span class="string">"best_iter"</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">do_at_exit</span><span class="params">()</span>:</span></span><br><span class="line">            _dict = &#123;<span class="string">"Q"</span>: self.Q,</span><br><span class="line">                     <span class="string">"iters"</span>: self.game.record.iters,</span><br><span class="line">                     <span class="string">"best_iter"</span>: self.game.record.best_iter&#125;</span><br><span class="line">            pickle.dump(_dict, open(self.memo, <span class="string">'wb'</span>))</span><br><span class="line"></span><br><span class="line">        atexit.register(do_at_exit)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># this method is auto called every 0.05s by the pyglet</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.game.state == <span class="string">'PLAY'</span>:</span><br><span class="line">            self.tapped = <span class="literal">False</span></span><br><span class="line">            <span class="comment"># call plan() to execute your plan</span></span><br><span class="line">            self.plan(self.get_state())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            state = self.get_state()</span><br><span class="line">            bird_state = list(state[<span class="string">'bird'</span>])</span><br><span class="line">            bird_state[<span class="number">2</span>] = <span class="string">'dead'</span></span><br><span class="line">            state[<span class="string">'bird'</span>] = bird_state</span><br><span class="line">            <span class="comment"># do NOT allow tap</span></span><br><span class="line">            self.tapped = <span class="literal">True</span></span><br><span class="line">            self.plan(state)</span><br><span class="line">            <span class="comment"># restart game</span></span><br><span class="line">            <span class="keyword">print</span> <span class="string">'iters:'</span>,self.game.record.iters,<span class="string">' score:'</span>, self.game.record.get(), <span class="string">'best: '</span>, self.game.record.best_score</span><br><span class="line">            self.game.record.inc_iters()</span><br><span class="line">            self.game.restart()</span><br><span class="line">            self.game.play()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get the state that robot needed</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_state</span><span class="params">(self)</span>:</span></span><br><span class="line">        state = &#123;&#125;</span><br><span class="line">        <span class="comment"># bird's position and status(dead or alive)</span></span><br><span class="line">        state[<span class="string">'bird'</span>] = (int(round(self.game.bird.x)), \</span><br><span class="line">                int(round(self.game.bird.y)), <span class="string">'alive'</span>)</span><br><span class="line">        state[<span class="string">'pipes'</span>] = []</span><br><span class="line">        <span class="comment"># pipes' position</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(self.game.pipes), <span class="number">2</span>):</span><br><span class="line">            p = self.game.pipes[i]</span><br><span class="line">            <span class="keyword">if</span> p.x &lt; Game.WINDOW_WIDTH:</span><br><span class="line">                <span class="comment"># this pair of pipes shows on screen</span></span><br><span class="line">                x = int(round(p.x))</span><br><span class="line">                y = int(round(p.y))</span><br><span class="line">                state[<span class="string">'pipes'</span>].append((x, y))</span><br><span class="line">                state[<span class="string">'pipes'</span>].append((x, y - Game.PIPE_HEIGHT_INTERVAL))</span><br><span class="line">        <span class="keyword">return</span> state</span><br><span class="line"></span><br><span class="line">    <span class="comment"># simulate the click action, bird will fly higher when tapped</span></span><br><span class="line">    <span class="comment"># It can be called only once every time slice(every execution cycle of plan())</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tap</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.tapped:</span><br><span class="line">            self.game.bird.jump()</span><br><span class="line">            self.tapped = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># That's where the robot actually works</span></span><br><span class="line">    <span class="comment"># NOTE Put your code here</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plan</span><span class="params">(self, state)</span>:</span></span><br><span class="line">        x = state[<span class="string">'bird'</span>][<span class="number">0</span>]</span><br><span class="line">        y = state[<span class="string">'bird'</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> len(state[<span class="string">'pipes'</span>]) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> y &lt; self.WINDOW_HEIGHT / <span class="number">2</span>:</span><br><span class="line">                self.tap()</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        h, v = <span class="number">9999</span>, <span class="number">9999</span></span><br><span class="line">        reward = <span class="number">-1000</span> <span class="keyword">if</span> state[<span class="string">'bird'</span>][<span class="number">2</span>] == <span class="string">'dead'</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(state[<span class="string">'pipes'</span>]), <span class="number">2</span>):</span><br><span class="line">            p = state[<span class="string">'pipes'</span>][i]</span><br><span class="line">            <span class="keyword">if</span> x &lt;= p[<span class="number">0</span>] + self.PIPE_WIDTH:</span><br><span class="line">                h = p[<span class="number">0</span>] + self.PIPE_WIDTH - x</span><br><span class="line">                v = p[<span class="number">1</span>] - y</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        scale = <span class="number">10</span></span><br><span class="line">        h /= scale</span><br><span class="line">        v /= scale</span><br><span class="line">        self.Q.setdefault((h, v), &#123;<span class="string">'tap'</span>: <span class="number">0</span>, <span class="string">'do_nothing'</span>: <span class="number">0</span>&#125;)</span><br><span class="line">        self.Q.setdefault(self.pre_s, &#123;<span class="string">'tap'</span>: <span class="number">0</span>, <span class="string">'do_nothing'</span>: <span class="number">0</span>&#125;)</span><br><span class="line">        tap_v = self.Q[(h, v)][<span class="string">'tap'</span>]</span><br><span class="line">        nothing_v = self.Q[(h, v)][<span class="string">'do_nothing'</span>]</span><br><span class="line">        self.Q[self.pre_s][self.pre_a] += self.alpha * (reward + max(tap_v, nothing_v) - self.Q[self.pre_s][self.pre_a])</span><br><span class="line">        self.pre_s = (h, v)</span><br><span class="line">        <span class="keyword">if</span> random.randint(<span class="number">0</span>, self.explore) &gt; <span class="number">100</span>:</span><br><span class="line">            self.pre_a = <span class="string">"do_nothing"</span> <span class="keyword">if</span> random.randint(<span class="number">0</span>, <span class="number">1</span>) <span class="keyword">else</span> <span class="string">"tap"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tap_v = self.Q[self.pre_s][<span class="string">'tap'</span>]</span><br><span class="line">            nothing_v = self.Q[self.pre_s][<span class="string">'do_nothing'</span>]</span><br><span class="line">            self.pre_a = <span class="string">"do_nothing"</span> <span class="keyword">if</span> tap_v &lt;= nothing_v <span class="keyword">else</span> <span class="string">"tap"</span></span><br><span class="line">        <span class="keyword">if</span> self.pre_a == <span class="string">'tap'</span>:</span><br><span class="line">            self.tap()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span>  </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    show_window = <span class="literal">True</span></span><br><span class="line">    enable_sound = <span class="literal">False</span></span><br><span class="line">    game = Game()</span><br><span class="line">    game.set_sound(enable_sound)</span><br><span class="line">    bot = Bot(game)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(dt)</span>:</span></span><br><span class="line">        game.update(dt)</span><br><span class="line">        bot.run()</span><br><span class="line">    pyglet.clock.schedule_interval(update, Game.TIME_INTERVAL)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> show_window:</span><br><span class="line">        window = pyglet.window.Window(Game.WINDOW_WIDTH, Game.WINDOW_HEIGHT, vsync = <span class="literal">False</span>)</span><br><span class="line"><span class="meta">        @window.event</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">on_draw</span><span class="params">()</span>:</span></span><br><span class="line">            window.clear()</span><br><span class="line">            game.draw()</span><br><span class="line">        pyglet.app.run()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pyglet.app.run()</span><br></pre></td></tr></table></figure><p>全部代码见<a href="https://github.com/BENULL/FlappyBirdBot" target="_blank" rel="noopener">github仓库</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://sarvagyavaish.github.io/FlappyBirdRL/" target="_blank" rel="noopener">Flappy Bird RL</a></li><li><a href="https://www.zhihu.com/question/26408259/answer/123230350" target="_blank" rel="noopener">如何用简单例子讲解 Q - learning 的具体过程？ - 牛阿的回答 - 知乎</a></li><li><a href="https://blog.csdn.net/qq_30615903/article/details/80739243" target="_blank" rel="noopener">Q-Learning算法详解</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基于Q-Learning-的FlappyBird-AI&quot;&gt;&lt;a href=&quot;#基于Q-Learning-的FlappyBird-AI&quot; class=&quot;headerlink&quot; title=&quot;基于Q-Learning 的FlappyBird AI&quot;&gt;&lt;/a&gt;基于Q-L
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="强化学习" scheme="http://yoursite.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Q-Learning" scheme="http://yoursite.com/tags/Q-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Scala 的几种group集合操作</title>
    <link href="http://yoursite.com/2020/12/20/Scala%E7%9A%84%E5%87%A0%E7%A7%8Dgroup%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2020/12/20/Scala%E7%9A%84%E5%87%A0%E7%A7%8Dgroup%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C/</id>
    <published>2020-12-20T15:33:29.000Z</published>
    <updated>2020-12-20T15:33:10.284Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Scala-的几种group集合操作"><a href="#Scala-的几种group集合操作" class="headerlink" title="Scala 的几种group集合操作"></a>Scala 的几种group集合操作</h1><p>scala的集合中有如下几种group操作</p><ul><li><p><code>groupBy</code> 按特定条件对集合元素进行分类</p></li><li><p><code>grouped</code> 将集合拆分成指定长度的子集合</p></li><li><p><code>groupMap</code> 使用方法按特定条件对集合的元素进行分类并处理每个元素</p></li><li><code>groupMapReduce</code> 使用方法按特定条件对集合中的元素进行分类，分别进行处理，最后将它们reduce</li></ul><p>这些方法在<a href="https://www.scala-lang.org/api/current/scala/collection/IterableOps.html" target="_blank" rel="noopener">scala.collection.IterableOps</a>中定义</p><h2 id="groupBy"><a href="#groupBy" class="headerlink" title="groupBy"></a>groupBy</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupBy</span></span>[<span class="type">K</span>](f: (<span class="type">A</span>) =&gt; <span class="type">K</span>): immutable.<span class="type">Map</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br></pre></td></tr></table></figure><p>返回immutable Map，每个Map由一个键和一个原始类型的值的集合组成</p><p>为了在生成的Map中处理这个值的集合，Scala提供了mapValues方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapValues</span></span>[<span class="type">W</span>](f: (<span class="type">V</span>) =&gt; <span class="type">W</span>): <span class="type">Map</span>[<span class="type">K</span>, <span class="type">W</span>]</span><br></pre></td></tr></table></figure><p>这个groupBy / mapValues组合对于处理从分组生成的Map的值非常方便</p><p>但是从Scala 2.13开始，方法mapValues不再可用</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Example: groupBy</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Pet</span>(<span class="params">species: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"> </span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">pets</span> </span>= <span class="type">List</span>(</span><br><span class="line">  <span class="type">Pet</span>(<span class="string">"cat"</span>, <span class="string">"sassy"</span>, <span class="number">2</span>), <span class="type">Pet</span>(<span class="string">"cat"</span>, <span class="string">"bella"</span>, <span class="number">3</span>), </span><br><span class="line">  <span class="type">Pet</span>(<span class="string">"dog"</span>, <span class="string">"poppy"</span>, <span class="number">3</span>), <span class="type">Pet</span>(<span class="string">"dog"</span>, <span class="string">"bodie"</span>, <span class="number">4</span>), <span class="type">Pet</span>(<span class="string">"dog"</span>, <span class="string">"poppy"</span>, <span class="number">2</span>), </span><br><span class="line">  <span class="type">Pet</span>(<span class="string">"bird"</span>, <span class="string">"coco"</span>, <span class="number">2</span>), <span class="type">Pet</span>(<span class="string">"bird"</span>, <span class="string">"kiwi"</span>, <span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">pets.groupBy(_.species)</span><br><span class="line"></span><br><span class="line"><span class="comment">// res5: scala.collection.immutable.Map[String,List[Pet]] = HashMap(</span></span><br><span class="line"><span class="comment">//bird -&gt; List(Pet(bird,coco,2), Pet(bird,kiwi,1)), </span></span><br><span class="line"><span class="comment">//dog -&gt; List(Pet(dog,poppy,3), Pet(dog,bodie,4), Pet(dog,poppy,2)), </span></span><br><span class="line"><span class="comment">//cat -&gt; List(Pet(cat,sassy,2), Pet(cat,bella,3)))</span></span><br></pre></td></tr></table></figure><p>groupBy / mapValues组合</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Example: groupBy and mapValues</span></span><br><span class="line">pets.groupBy(_.species).mapValues(_.map(_.name)).toMap</span><br><span class="line"></span><br><span class="line"><span class="comment">// warning: method mapValues in trait MapOps is deprecated (since 2.13.0): Use .view.mapValues(f). A future // // version will include a strict version of this method (for now, .view.mapValues(f).toMap).</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// val res7: scala.collection.immutable.Map[String,List[String]] = Map(</span></span><br><span class="line"><span class="comment">// bird -&gt; List(coco, kiwi), </span></span><br><span class="line"><span class="comment">//dog -&gt; List(poppy, bodie, poppy), </span></span><br><span class="line"><span class="comment">//cat -&gt; List(sassy, bella))</span></span><br></pre></td></tr></table></figure><h2 id="groupMap"><a href="#groupMap" class="headerlink" title="groupMap"></a>groupMap</h2><p>出现了一种新方法groupMap，按特定条件对集合的元素进行分类并处理每个元素</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupMap</span></span>[<span class="type">K</span>, <span class="type">B</span>](key: (<span class="type">A</span>) =&gt; <span class="type">K</span>)(f: (<span class="type">A</span>) =&gt; <span class="type">B</span>): immutable.<span class="type">Map</span>[<span class="type">K</span>, <span class="type">CC</span>[<span class="type">B</span>]]</span><br></pre></td></tr></table></figure><p>对比上面的mapValues方法<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Example: groupMap</span></span><br><span class="line">pets.groupMap(_.species)(_.name)</span><br><span class="line"></span><br><span class="line"><span class="comment">// val res8: scala.collection.immutable.Map[String,List[String]] = Map(</span></span><br><span class="line"><span class="comment">//cat -&gt; List(sassy, bella), </span></span><br><span class="line"><span class="comment">//bird -&gt; List(coco, kiwi), </span></span><br><span class="line"><span class="comment">//dog -&gt; List(poppy, bodie, poppy))</span></span><br></pre></td></tr></table></figure></p><h2 id="groupMapReduce"><a href="#groupMapReduce" class="headerlink" title="groupMapReduce"></a>groupMapReduce</h2><p>有时，我们需要在对集合进行分组后对Map值进行reduce</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupMapReduce</span></span>[<span class="type">K</span>, <span class="type">B</span>](key: (<span class="type">A</span>) =&gt; <span class="type">K</span>)(f: (<span class="type">A</span>) =&gt; <span class="type">B</span>)(reduce: (<span class="type">B</span>, <span class="type">B</span>) =&gt; <span class="type">B</span>): immutable.<span class="type">Map</span>[<span class="type">K</span>, <span class="type">B</span>]</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Example groupMapReduce</span></span><br><span class="line">pets.groupMapReduce(_.species)(_ =&gt; <span class="number">1</span>)(_ + _)</span><br><span class="line"></span><br><span class="line"><span class="comment">//val res9: scala.collection.immutable.Map[String,Int] = Map(</span></span><br><span class="line"><span class="comment">//cat -&gt; 2, </span></span><br><span class="line"><span class="comment">//bird -&gt; 2, </span></span><br><span class="line"><span class="comment">//dog -&gt; 3)</span></span><br></pre></td></tr></table></figure><h2 id="grouped"><a href="#grouped" class="headerlink" title="grouped"></a>grouped</h2><p>集合拆分成指定长度的子集合</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grouped</span></span>(size: <span class="type">Int</span>): <span class="type">Iterator</span>[<span class="type">C</span>]</span><br></pre></td></tr></table></figure><p>尝试将一个长度为9的集合进行切分</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">list.grouped(<span class="number">4</span>).toList</span><br><span class="line"></span><br><span class="line"><span class="comment">// val res11: List[List[Int]] = List(List(1, 2, 3, 4), List(5, 6, 7, 8), List(9))</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Scala-的几种group集合操作&quot;&gt;&lt;a href=&quot;#Scala-的几种group集合操作&quot; class=&quot;headerlink&quot; title=&quot;Scala 的几种group集合操作&quot;&gt;&lt;/a&gt;Scala 的几种group集合操作&lt;/h1&gt;&lt;p&gt;scala的
      
    
    </summary>
    
    
      <category term="BigData" scheme="http://yoursite.com/categories/BigData/"/>
    
    
      <category term="Scala" scheme="http://yoursite.com/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Feedback Graph Convolutional Network for Skeleton-based Action Recognition</title>
    <link href="http://yoursite.com/2020/12/16/FGCN/"/>
    <id>http://yoursite.com/2020/12/16/FGCN/</id>
    <published>2020-12-15T20:42:22.000Z</published>
    <updated>2020-12-16T06:31:22.031Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Feedback-Graph-Convolutional-Network-for-Skeleton-based-Action-Recognition"><a href="#Feedback-Graph-Convolutional-Network-for-Skeleton-based-Action-Recognition" class="headerlink" title="Feedback Graph Convolutional Network for Skeleton-based Action Recognition"></a>Feedback Graph Convolutional Network for Skeleton-based Action Recognition</h1><blockquote><p>作者          | Hao Yang, Dan Yan<br>单位          | NUCTECH Company Limited<br>论文地址 ｜<a href="https://arxiv.org/abs/2003.07564" target="_blank" rel="noopener">https://arxiv.org/abs/2003.07564</a></p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​    近年来，许多学者利用图卷积网络（GCN）对骨架序列进行端到端优化建模。然而，传统的gcn是前馈网络，浅层不能访问到深层的语义信息，在这篇论文中，提出一个新的网络，称为<strong>反馈图卷积网络（FGCN）</strong></p><p>这是<strong>首次</strong>将反馈机制引入GCNs和动作识别中</p><p><strong>与传统的gcn相比，FGCN具有以下优点</strong></p><ol><li><p>设计了一种多阶段的时间采样策略，以从粗到精的渐进过程提取动作识别的时空特征</p></li><li><p>提出了一种基于稠密连接的反馈图卷积块（FGCB）来引入反馈连接,它将高层语义特征传递到底层，并逐级传递时间信息，逐步建立全局时空特征模型，用于动作识别</p></li><li><p>FGCN模型提供了早期预测。在早期阶段，模型接收到关于动作的部分信息。当然，它的预测相对粗糙。将粗预测视为先验知识，指导后期特征学习，实现精确预测</p></li></ol><p>在NTU-RGB+D、NTU-RGB+D120和Northwestern-UCLA的数据集上进行了大量的实验，结果表明所提出的FGCN对动作识别是有效的。它在三个数据集上达到了最先进的性能</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>​    近年来，从不同终端上传的视频数量已经增加。这推动了对基于视频内容的人类行为分析的迫切需求。尤其是与RGB和光流等其他模式相比，骨架人体行为识别因其对动态环境和复杂背景的影响具有较强的适应性而吸引了许多计算机视觉研究者。早期使用骨骼进行动作识别的深度学习方法通常将骨骼数据表示为关节坐标向量序列或伪图像，然后分别由RNN或CNN建模</p><p>​    然而，这些方法并没有显式地利用相关关节之间的空间依赖性，即使空间依赖性对于理解人类行为是有用的。最近，一些方法根据连续帧的自然连接和时间边缘来构造时空图。然后他们利用GCN来模拟时空特征。然而，<strong>传统的gcn都是单个前馈网络</strong>，由整个骨架序列当作输入。这些方法很难提取出有效的时空特征，因为这些有用的信息通常被隐藏在与运动无关或未区分的片段中。例如，在“踢某物”动作中，大多数片段是“直立站立”，而在“穿鞋”动作中，大多数片段都是坐在椅子上。因此，对于低层，单通前馈网络无法访问深层语义信息。同时，输入整个骨架序列增加了模型的计算复杂度。</p><p>​    基于这一点，提出了一种新的神经网络，称为反馈图卷积网络(FGCN)，以粗到精的渐进过程从骨架数据中提取有效的时空特征，用于动作识别。<strong>FGCN是第一个将反馈机制引入GCNs和动作识别的工作</strong>。与传统的gcn相比，FGCN具有多阶段的时间采样策略，该策略将输入的骨架序列在时域内分为多个阶段，并从时域对输入的骨架片段进行稀疏采样，避免了整个骨架序列的输入。对每一级输入的空时图像进行局部卷积提取。提出了一种基于反馈图卷积块（FGCB）融合局部特征的全局时空特征建模方法。FGCB是一个局部稠密图卷积网络，每个级到下一级都有横向连接，它将反馈连接引入到传统的gcn中。从语义角度看，它是自上而下的工作方式，这使得低层卷积层能够在每个阶段访问高层的语义信息。在时域上，FGCB的反馈机制具有一系列因果关系，前一级的输出流入下一级，以调节其输入。</p><p>​    <strong>FGCN的另一个优点是它可以在总推理时间的一小部分时间内提供输出的早期预测</strong>。这在许多应用中都很有价值，例如机器人或自动驾驶，在这些应用中，延迟时间是非常关键的。早期预测是所提出的多阶段从粗到细逐步优化的结果。在早期阶段，FGCN只提供了一部分骨架序列，而且有关该行为的信息有限，因此其推断相对粗糙。这些推理被视为在以后阶段指导特征学习的先验知识。在后期阶段，该模型接收到更完整的行为信息和先前推理的引导者信息，从而输出更精确的推理。提出了几种时域融合策略，将局部预测融合到视频级预测中。这些策略使网络在渐进过程中得到优化。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="反馈图卷积网络"><a href="#反馈图卷积网络" class="headerlink" title="反馈图卷积网络"></a>反馈图卷积网络</h3><p>​    传统的基于GCNs的动作识别方法都是在一个前馈网络中输入整个骨架序列。然而，当输入整个骨架序列时，有用的信息通常隐藏在与运动无关且无差别的片段中。单通前馈网络不能在浅层访问语义信息。为了解决这些问题，提出了一种反馈图卷积网络（FGCN），该网络通过多级递进过程提取时空特征。具体地说，FGCN设计了一种多阶段的时间采样策略来从骨架数据中稀疏地采样一系列输入片段，而不是直接对整个骨架序列进行操作。这些片段首先被输入到图的卷积层中以提取局部时空特征。然后，提出了一种反馈图卷积块（FGCB），通过将前一级的高级信息传输到下一级来调制其输入，从而融合来自多个时间阶段的局部时空特征。最后，提出了几种时间融合策略，将所有时间阶段的局部预测进行融合，给出一个视频级的预测。</p><p><img src="https://img-blog.csdnimg.cn/20201216040747929.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20201216040804695.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="反馈图卷积块（FGCB"><a href="#反馈图卷积块（FGCB" class="headerlink" title="反馈图卷积块（FGCB)"></a>反馈图卷积块（FGCB)</h3><p>​    反馈模块FGCB是FGCN模型的核心部分。一方面，FGCB将高层语义信息传回低层，以细化其编码特征。另一方面，前一级的输出流入下一级，以调节其输入。为了使FGCB能够有效地将信息从高层传输到低层，以及从前一个阶段传输到下一个阶段，提出了一个密集连接的局部图卷积网络，它增加了从每一层到所有后续层的连接</p><p><img src="https://img-blog.csdnimg.cn/20201216040814776.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>设计了四个消融实验来评估不同超参数、结构和输入对FGCN模型性能的影响。这些消融实验都是在NTU-RGB+D上进行的</p><h3 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h3><p>​    所有实验均采用PyTorch深度学习框架实现。训练过程中采用随机梯度下降（SGD）优化器，batch-size为32，momentum为0.9，初始学习率为0.1。在第40和60 个epoch，学习率除以10。训练过程在第80 epoch结束</p><p>​    输入的视频在时间上分为五个阶段，每个阶段随机抽取64个连续的帧组成一个输入片段。十个图卷积层堆叠在反馈块FGCB的前面，这些层具有与ST-GCN中的图卷积层相同的配置。FGCB有四个图形卷积层（即L=4）,将它们的时空核大小和输出通道分别设置为ks=3、kt=3和m=256<br><img src="https://img-blog.csdnimg.cn/20201216040830492.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="请添加图片描述"><br><img src="https://img-blog.csdnimg.cn/20201216040830441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="请添加图片描述"><br><img src="https://img-blog.csdnimg.cn/20201216040830561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="请添加图片描述"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Feedback-Graph-Convolutional-Network-for-Skeleton-based-Action-Recognition&quot;&gt;&lt;a href=&quot;#Feedback-Graph-Convolutional-Network-for-Skele
      
    
    </summary>
    
    
      <category term="Paper" scheme="http://yoursite.com/categories/Paper/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
      <category term="ActionRecognition" scheme="http://yoursite.com/tags/ActionRecognition/"/>
    
  </entry>
  
  <entry>
    <title>Temporal Extension Module for Skeleton-Based Action Recognition</title>
    <link href="http://yoursite.com/2020/12/10/TEM/"/>
    <id>http://yoursite.com/2020/12/10/TEM/</id>
    <published>2020-12-09T22:42:22.000Z</published>
    <updated>2020-12-09T22:35:28.561Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Temporal-Extension-Module-for-Skeleton-Based-Action-Recognition"><a href="#Temporal-Extension-Module-for-Skeleton-Based-Action-Recognition" class="headerlink" title="Temporal Extension Module for Skeleton-Based Action Recognition"></a>Temporal Extension Module for Skeleton-Based Action Recognition</h1><blockquote><p>作者 | Yuya Obinata and Takuma Yamamoto<br>单位         | FUJITSU LABORATORIES LTD<br>论文地址｜<a href="https://arxiv.org/abs/2003.08951" target="_blank" rel="noopener">https://arxiv.org/abs/2003.08951</a><br>ICPR2020</p></blockquote><p>在st-gcn的基础上开发了一个模块，在帧与帧之间相邻的关节点之间也添加连接，好处在于和其他网络结合起来很方便，对于性能也有一定的提高</p><p>但其实很多sota的模型都已经考虑过帧间关节点的链接，同时扩展到了多个尺度，不仅仅是帧间邻居关节点相连</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>提出了一个用于基于骨架的动作识别的的时域扩展模块</p><p><strong>现有的方法试图在帧内表示更合适的空间图，但忽略了帧间时间图的优化</strong></p><p>具体来说，这些方法只连接帧间同一关节对应的顶点。在这篇论文中，着重于在帧间添加与相邻多个顶点的连接</p><p>是提取人体运动中多个关节的相关特征的一种简单而有效的方法</p><p>主要贡献如下</p><ul><li>提出了一个时间扩展模块，用于帧间时态图的扩展。该模块在提取人体运动中连接的多个相邻关节的相关特征时简单而有效。</li><li>在消融实验中的展示了TEM有效性</li><li>达到了SOTA</li></ul><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>时空图卷积网络（ST-GCN）是第一个使用GCN对骨架序列进行动作识别的方法</p><p><img src="https://img-blog.csdnimg.cn/2020121006314185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>ST-GCN包括一个空间图和一个时间图，直接输入一个骨架序列，并从帧内和帧间的关节处提取特征</p><p>在这项工作中，着重于扩展时间图，连接相邻的多个顶点以及帧间（右）上的同一个顶点。在帧内提出了更合适的空间图，性能得到了显著提高。然而，这些方法忽略了帧间时间图的优化</p><p>传统的GCN方法将只对应于同一关节的顶点之间的时间维连接起来，该方法对于提取同一关节轨迹特征具有一定的效果，然而，由于过于简单不太能够提取帧间各关节间相关运动的特征</p><p><strong>研究目标</strong><br>优化空间图和时间图，以进一步提高性能<br>TEM模块不仅直接将边添加到同一个顶点，而且还直接向相邻的多个顶点添加边，并基于帧间相同的多个顶点计算卷积</p><h2 id="时间扩展模块"><a href="#时间扩展模块" class="headerlink" title="时间扩展模块"></a>时间扩展模块<img src="https://img-blog.csdnimg.cn/20201210063210320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></h2><p>在ST-GCN中加入了这个方法的模块，ST-GCN包括多层时空图卷积操作，将TEM放在空间卷积和时间卷积层中</p><p>以同样的方式很容易地TEM模块实现到基于时空图卷积的网络中</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验<img src="https://img-blog.csdnimg.cn/20201210063232136.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></h2><p>加上这个模块后有一定的性能提升</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Temporal-Extension-Module-for-Skeleton-Based-Action-Recognition&quot;&gt;&lt;a href=&quot;#Temporal-Extension-Module-for-Skeleton-Based-Action-Recog
      
    
    </summary>
    
    
      <category term="Paper" scheme="http://yoursite.com/categories/Paper/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
      <category term="ActionRecognition" scheme="http://yoursite.com/tags/ActionRecognition/"/>
    
  </entry>
  
  <entry>
    <title>Contextual Residual Aggregation for Ultra High-Resolution Image Inpainting</title>
    <link href="http://yoursite.com/2020/12/09/CRA%20_for_image_inpanting/"/>
    <id>http://yoursite.com/2020/12/09/CRA%20_for_image_inpanting/</id>
    <published>2020-12-09T10:02:22.000Z</published>
    <updated>2020-12-09T10:02:22.948Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Contextual-Residual-Aggregation-for-Ultra-High-Resolution-Image-Inpainting"><a href="#Contextual-Residual-Aggregation-for-Ultra-High-Resolution-Image-Inpainting" class="headerlink" title="Contextual Residual Aggregation for Ultra High-Resolution Image Inpainting"></a>Contextual Residual Aggregation for Ultra High-Resolution Image Inpainting</h1><blockquote><p>作者 | Zili Yi, Qiang Tang, Shekoofeh Azizi, Daesik Jang, Zhan Xu<br>单位 | 华为技术有限公司（加拿大）<br>代码 | <a href="https://github.com/Ascend-Huawei/Ascend-Canada/tree/master/Models/Research_HiFIll_Model" target="_blank" rel="noopener">https://github.com/Ascend-Huawei/Ascend-Canada/tree/master/Models/Research_HiFIll_Model</a><br>论文地址｜<a href="https://arxiv.org/abs/2005.09704" target="_blank" rel="noopener">https://arxiv.org/abs/2005.09704</a><br>备注 | CVPR 2020 Oral </p></blockquote><h2 id="图像修复"><a href="#图像修复" class="headerlink" title="图像修复"></a>图像修复</h2><p>自动填充图像中缺失部分</p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ul><li>调整目标位置</li><li>移除不想要的元素</li><li>修复损坏的图像</li></ul><p><img src="https://img-blog.csdnimg.cn/2020120917523752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="当前的方法"><a href="#当前的方法" class="headerlink" title="当前的方法"></a>当前的方法</h3><ol><li><p>通过复制来填充</p><ul><li><p>从缺失部分附近“借”像素来进行填充</p></li><li><p>e.g., PatchMatch, diffusion-based</p></li></ul></li><li>通过建模来填充<ul><li>数据驱动的方式来学习缺失的像素</li><li>e.g., PixelRNN,FCN</li></ul></li><li>结合上面两种<ul><li>e.g., DeepFill, Patch-Swap</li><li>这篇文章的方法</li></ul></li></ol><h4 id="当前基于学习的方法的不足"><a href="#当前基于学习的方法的不足" class="headerlink" title="当前基于学习的方法的不足"></a>当前基于学习的方法的不足</h4><ul><li>不能够去处理高分辨率图像<ul><li>训练困难</li><li>GPU/NPU内存的限制</li><li>缺少高分辨率的训练数据集</li></ul></li></ul><p><img src="https://img-blog.csdnimg.cn/20201209175251686.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="论文方法"><a href="#论文方法" class="headerlink" title="论文方法"></a>论文方法</h2><p>提出了一种上下文残差聚合（CRA）机制，该机制可以通过对上下文补丁中的残差进行加权聚合来生成丢失内容的高频残差，因此网络的训练仅需要低分辨率即可</p><p>由于神经网络的卷积层仅需要在低分辨率的输入和输出上进行操作，因此降低了内存和计算能力的成本</p><p>此外，还减轻了对高分辨率训练数据集的需求</p><p><strong>通过3阶段的pipeline实现高分辨率图像的修复</strong></p><ol><li><p>由生成器（Generator）得到低分辨率的修补好的图像</p></li><li><p>通过残差聚合模块得到高频残差</p></li><li><p>合并高频残差和低分辨率修补结果得到高分辨率修补图像</p></li></ol><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="https://img-blog.csdnimg.cn/20201209175306706.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="生成器（Generator）"><a href="#生成器（Generator）" class="headerlink" title="生成器（Generator）"></a>生成器（Generator）</h4><p><strong>两阶段的coarse-to-fine网络</strong></p><p>coarse network输入下采样到256×256的带mask图像，会产生粗略的缺失内容</p><p>fine network 通过<strong>Attention Computing Module (ACM)</strong>和<strong>Attention Transfer Module (ATM)</strong>得到缺失部分内外的关系得分，输出512×512的修复结果</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://img-blog.csdnimg.cn/20201209175321384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>这篇论文的方法在图片分辨率大于1K的情况下修复效率和质量达到了最好</strong></p><p><img src="https://img-blog.csdnimg.cn/20201209175343504.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="使用预训练好模型的测试结果"><a href="#使用预训练好模型的测试结果" class="headerlink" title="使用预训练好模型的测试结果"></a>使用预训练好模型的测试结果</h4><p>结果在缺失部分很大，且上下文环境复杂的情况下，效果看起来并没有很好</p><p>在背景单一的风景照中效果很不错<br><img src="https://img-blog.csdnimg.cn/20201209175353108.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li><p>提出了一种新颖的上下文残留聚合技术，可对超高分辨率图像进行更高效和高质量的修复</p></li><li><p>把大图下采样到 512×512 ，在分辨率为512×512的小图像上进行图像修复，然后在高分辨率图像上进行推理得到修复效果良好的大图</p></li><li>与其他数据驱动方法不同，分辨率和孔尺寸的增加不会降低修补质量，也不会显着增加我们框架中的处理时间</li><li>到目前为止，是唯一能够在超高分辨率图像(4K至8K)上进行端到端修复的基于学习的技术</li></ul><p>  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Contextual-Residual-Aggregation-for-Ultra-High-Resolution-Image-Inpainting&quot;&gt;&lt;a href=&quot;#Contextual-Residual-Aggregation-for-Ultra-High
      
    
    </summary>
    
    
      <category term="Paper" scheme="http://yoursite.com/categories/Paper/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
      <category term="ImageInpainting" scheme="http://yoursite.com/tags/ImageInpainting/"/>
    
  </entry>
  
  <entry>
    <title>K-means聚类算法</title>
    <link href="http://yoursite.com/2020/11/25/K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2020/11/25/K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</id>
    <published>2020-11-25T10:34:22.000Z</published>
    <updated>2020-11-25T10:45:24.703Z</updated>
    
    <content type="html"><![CDATA[<h1 id="K-means聚类算法"><a href="#K-means聚类算法" class="headerlink" title="K-means聚类算法"></a>K-means聚类算法</h1><h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><blockquote><p>在无监督学习中, 训练样本的标记信息是未知的, 目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律, 为进一步的数据分析提供基础，此类学习任务中研究最多、应用最广的是“聚类”(clustering)</p></blockquote><p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集, 每个子集称为一个“簇”(cluster)</p><p>通过这样的划分, 每个簇可能对应于一些潜在的概念(类别), 需说明的是, 这些概念对聚类算法而言事先是未知的, 聚类过程仅能自动形成簇结构, 簇所对应的概念语义需由使用者来把握</p><p>关于簇的完整定义尚未达成共识，传统的定义如下</p><ul><li><p>同一簇中的实例必须尽可能相似</p></li><li><p>不同簇中的实例必须尽可能不同</p></li><li><p>相似度和相异度的度量必须清楚并具有实际意义</p></li></ul><h3 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h3><p>聚类性能度量大致有两类</p><ul><li><p>将聚类结果与某个参考模型进行比较, 称为“外部指标” (external index)</p></li><li><p>直接考察聚类结果而不利用任何参考模型, 称为“内部指标” (internalindex)</p></li></ul><h4 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h4><p>对数据集 <script type="math/tex">D=\left\{\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \ldots, \boldsymbol{x}_{m}\right\},</script> 假定通过聚类给出的族划分为 <script type="math/tex">\mathcal{C}=\left\{C_{1},C_{2}, \ldots, C_{k}\right\},</script> 参考模型给出的族划分为 <script type="math/tex">\mathcal{C}^{*}=\left\{C_{1}^{*}, C_{2}^{*}, \ldots, C_{s}^{*}\right\} .</script> 相应地, 令 <script type="math/tex">\boldsymbol{\lambda}</script> 与<script type="math/tex">\lambda^{*}</script> 分别表示与 <script type="math/tex">\mathcal{C}</script> 和 <script type="math/tex">\mathcal{C}^{*}</script> 对应的族标记向量. 我们将样本两两配对考虑, 定义</p><script type="math/tex; mode=display">\begin{aligned}a &\left.=|S S|, \quad S S=\left\{\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \mid \lambda_{i}=\lambda_{j}, \lambda_{i}^{*}=\lambda_{j}^{*}, i<j\right)\right\} \\b &\left.=|S D|, \quad S D=\left\{\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \mid \lambda_{i}=\lambda_{j}, \lambda_{i}^{*} \neq \lambda_{j}^{*}, i<j\right)\right\} \\c &\left.=|D S|, \quad D S=\left\{\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \mid \lambda_{i} \neq \lambda_{j}, \lambda_{i}^{*}=\lambda_{j}^{*}, i<j\right)\right\} \\d &\left.=|D D|, \quad D D=\left\{\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \mid \lambda_{i} \neq \lambda_{j}, \lambda_{i}^{*} \neq \lambda_{j}^{*}, i<j\right)\right\}\end{aligned}</script><p>其中集合 <script type="math/tex">SS</script> 包含了在 <script type="math/tex">\mathcal{C}</script> 中隶属于相同族且在 <script type="math/tex">\mathcal{C}^{*}</script> 中也隶属于相同族的样本</p><p>集合 <script type="math/tex">SD</script> 包含了在 <script type="math/tex">\mathcal{C}</script> 中隶属于相同族但在 <script type="math/tex">\mathcal{C}^{*}</script> 中隶属于不同族的样本</p><p>集合 <script type="math/tex">DS</script> 包含了在 <script type="math/tex">\mathcal{C}</script> 中隶属于 不同族但在 <script type="math/tex">\mathcal{C}^{*}</script> 中隶属于相同族的样本</p><p>集合 <script type="math/tex">DD</script> 包含了在 <script type="math/tex">\mathcal{C}</script> 中隶属于不同族在 <script type="math/tex">\mathcal{C}^{*}</script> 中也隶属于不同族的样本</p><p>可计算出下面这些聚类性能度量外部指标</p><ul><li>Jaccard系数</li></ul><script type="math/tex; mode=display">\mathrm{JC}=\frac{a}{a+b+c}</script><ul><li><p>FM指数（Fowlkes and Mallows Index,FMI）</p><script type="math/tex; mode=display">\mathrm{FMI}=\sqrt{\frac{a}{a+b} \cdot \frac{a}{a+c}}</script></li><li><p>Rand指数(Rand Index,RI)</p><script type="math/tex; mode=display">\mathrm{RI}=\frac{2(a+d)}{m(m-1)}</script></li></ul><p>显然上述性能度量的结果值均在[0，1]区间，值越大越好</p><h4 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h4><p>考虑聚类结果的族划分 <script type="math/tex">\mathcal{C}=\left\{C_{1}, C_{2}, \ldots, C_{k}\right\},</script> 定义</p><script type="math/tex; mode=display">\begin{aligned}\operatorname{avg}(C) &=\frac{2}{|C|(|C|-1)} \sum_{1 \leqslant i<j \leqslant|C|} \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \\\operatorname{diam}(C) &=\max _{1 \leqslant i<j \leqslant|C|} \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \\d_{\min }\left(C_{i}, C_{j}\right) &=\min _{\boldsymbol{x}_{i} \in C_{i}, \boldsymbol{x}_{j} \in C_{j}} \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \\d_{\operatorname{cen}}\left(C_{i}, C_{j}\right) &=\operatorname{dist}\left(\boldsymbol{\mu}_{i}, \boldsymbol{\mu}_{j}\right)\end{aligned}</script><p>其中dist <script type="math/tex">(\cdot, \cdot)</script> 用于计算两个样本之间的距离<script type="math/tex">\boldsymbol{\mu}</script><br>族 <script type="math/tex">C</script> 的中心点 <script type="math/tex">\boldsymbol{\mu}=</script> <script type="math/tex">\frac{1}{|C|} \sum_{1 \leqslant i \leqslant|C|} \boldsymbol{x}_{i}</script></p><p>族 <script type="math/tex">C</script> 内样本间的平均距离<script type="math/tex">\operatorname{avg}(C)</script> </p><p>族 <script type="math/tex">C</script> 内样本间的最远距离<script type="math/tex">\operatorname{diam}(C)</script> </p><p>对应于族 <script type="math/tex">C_{i}</script> 与族 <script type="math/tex">C_{j}</script> 最近样本间的距离 <script type="math/tex">d_{\min }\left(C_{i}, C_{j}\right)</script></p><p>对应于族 <script type="math/tex">C_{i}</script> 与族 <script type="math/tex">C_{j}</script> 中心点间的距离<script type="math/tex">d_{\mathrm{cen}}\left(C_{i}, C_{j}\right)</script> </p><p>可计算出下面这些聚类性能度量内部指标</p><ul><li>DB 指数(Davies-Bouldin Index, DBI)<script type="math/tex; mode=display">\mathrm{DBI}=\frac{1}{k} \sum_{i=1}^{k} \max _{j \neq i}\left(\frac{\operatorname{avg}\left(C_{i}\right)+\operatorname{avg}\left(C_{j}\right)}{d_{\mathrm{cen}}\left(\mu_{i}, \mu_{j}\right)}\right)</script></li><li>Dunn 指数(Dunn Index, DI)<script type="math/tex; mode=display">\mathrm{DI}=\min _{1 \leqslant i \leqslant k}\left\{\min _{j \neq i}\left(\frac{d_{\min }\left(C_{i}, C_{j}\right)}{\max _{1 \leqslant l \leqslant k} \operatorname{diam}\left(C_{l}\right)}\right)\right\}</script>显然, DBI 的值越小越好, 而 DI 则相反, 值越大越好</li></ul><h3 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h3><p>可参考<a href="https://blog.csdn.net/qq_32815807/article/details/109172509" target="_blank" rel="noopener">k-近邻算法（KNN）</a>中距离度量部分</p><h3 id="常见的聚类算法"><a href="#常见的聚类算法" class="headerlink" title="常见的聚类算法"></a>常见的聚类算法</h3><h4 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h4><p>原型聚类亦称“基于原型的聚类” (prototype-based clustering)</p><p>假设聚类结构能通过一组原型（指样本空间中具有代表性的点）刻画, 通常情形下，算法先对原型进行初始化, 然后对原型进行迭代更新求解. 采用不同的原型表示、不同的求解方式将产生不同的算法，下面是几种著名的原型聚类算法</p><ul><li>k-means</li><li>学习向量量化（Learning Vector Quantization,LVQ）</li><li>高斯混合聚类（Mixture-of-Guassian）</li></ul><h4 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h4><p>层次聚类(hierarchical clustering)试图在不同层次对数据集进行划分，从而形成树形的聚类结构</p><p>数据集的划分可采用“自底向上”的聚合策略，它将最相似的两个点合并，直到所有点都合并到一个群集中为止</p><p>也可采用“自顶向下”的分拆策略，它以所有点作为一个簇开始，并在每一步拆分相似度最低的簇，直到仅剩下单个数据点</p><p>在分层聚类中，聚类数（k）通常由用户预先确定，通过在指定深度切割树状图来分配聚类，从而得到k组较小的树状图</p><p>与许多分区聚类技术不同，分层聚类是<strong>确定性</strong>过程，这意味着当您对相同的输入数据运行两次算法时，聚类分配不会改变</p><p>层次聚类方法的<strong>优点</strong>包括</p><ul><li>它们通常会揭示有关数据对象之间的更详细的信息。</li><li>它们提供了<strong>可解释的树状图</strong>。</li></ul><p>层次聚类方法的<strong>缺点</strong>包括</p><ul><li>算法复杂度高</li><li>对<strong>噪音</strong>和<strong>异常值</strong>很敏感</li></ul><h4 id="基于密度的聚类"><a href="#基于密度的聚类" class="headerlink" title="基于密度的聚类"></a>基于密度的聚类</h4><p>基于密度的聚类根据区域中数据点的密度确定聚类分配,在高密度的数据点被低密度区域分隔的地方分配簇</p><p>与其他类别的聚类不同，该方法不需要用户指定群集数量，而是有一个基于距离的参数充当可调阈值来确定是否将接近的点视为簇成员</p><p>DBSCAN是一种著名的密度聚类算法，它基于一组领域参数来刻画样本分布的紧密程度</p><p>基于密度的聚类方法的<strong>优点</strong>包括</p><ul><li>他们擅长识别<strong>非类圆型</strong>簇。</li><li>它们可以抵抗<strong>异常值</strong>。</li></ul><p>基于密度的聚类方法的<strong>缺点</strong>包括</p><ul><li>它们不太适合在<strong>高维空间中聚类</strong></li><li>很难确定<strong>密度不同的</strong>簇。</li></ul><h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><p>k均值聚类算法（k-means clustering algorithm）是一种迭代求解的聚类分析算法</p><p>它试图将数据集划分为K个不同的非重叠子组(簇)，其中每个数据点只属于一个组</p><p>同时使得簇内数据点尽可能相似，还要尽可能保持簇之间的差异</p><p>聚类分配的质量是通过计算质心<strong>收敛</strong>后的平方误差和（sum of the squared error,SSE）来确定的，或者与先前的迭代分配相符</p><p>SSE定义为每个点与其最接近的质心的欧几里德距离平方的总和，k-means的目的是尝试最小化该值</p><p>下图显示了在同一数据集上两次不同的<em>k</em> -means算法运行的前五个迭代中的质心和SSE更新：</p><p><img src="https://img-blog.csdnimg.cn/20201125183206829.gif#pic_center" alt="在这里插入图片描述"></p><p>此图的目的是表明质心的初始化是重要的一步，随机初始化步骤导致<em>k</em> -means算法<strong>不确定</strong>，这意味着如果您在同一数据集上运行两次相同的算法，则簇分配将有所不同</p><p>研究人员通常会对整个<em>k</em>均值算法进行几次初始化，并从具有最低SSE的初始化</p><h3 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h3><ol><li>指定簇数K</li><li>首先对数据集shuffle，然后为质心随机选择<em>K个</em>数据点</li><li>不断迭代，直到质心没有变化，即数据点分配给群集的操作没有改变<ul><li>计算数据点和所有质心之间的平方距离之和</li><li>将每个数据点分配给最近的群集（质心）</li><li>通过获取属于每个群集的所有数据点的平均值，计算群集的质心</li></ul></li></ol><p>k-means解决问题的方法称为期望最大化（Expectation Maximization,EM）<br>目标函数是</p><script type="math/tex; mode=display">E=\sum_{i=1}^{k} \sum_{\boldsymbol{x} \in C_{i}}\left\|\boldsymbol{x}-\boldsymbol{\mu}_{i}\right\|_{2}^{2}</script><p>其中 <script type="math/tex">\mu_{i}=\frac{1}{|C_{i}|} \sum_{x \in C_{i}} x</script> 是族 <script type="math/tex">C_{i}</script> 的均值向量<br>最小化目标函数并不容易, 找到它的最优解需考察样本集 <script type="math/tex">D</script> 所有可能的族划分, 这是一个 <script type="math/tex">\mathrm{NP}</script> 难问题</p><p>因此k-means算法采用了贪心策略, 通过迭代优化来近似求解</p><h3 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h3><ul><li>类别数 <script type="math/tex">k</script> 值需要预先指定，而在实际应用中最优的 <script type="math/tex">k</script> 值是不知道的,解决这个问题的一个方法是尝试用不同的 <script type="math/tex">k</script> 值聚类, 检验各自得到聚类结果的质量, 推测最优的 <script type="math/tex">k</script> 值</li><li><p>由于包括kmeans在内的聚类算法使用基于距离的度量来确定数据点之间的相似性，因此建议对数据进行标准化</p></li><li><p>由于kmeans算法可能停留在局部最优而不收敛于全局最优，因此不同的初始化可能导致不同的聚类，建议使用不同的质心初始化来运行算法，并选择产生较低SSE的运行结果</p></li></ul><h3 id="找到合适的K"><a href="#找到合适的K" class="headerlink" title="找到合适的K"></a>找到合适的K</h3><p>下面将介绍两个指标，这些指标可能使我们更直接的观察k的取值</p><h4 id="肘部法则（Elbow-Method"><a href="#肘部法则（Elbow-Method" class="headerlink" title="肘部法则（Elbow Method)"></a>肘部法则（Elbow Method)</h4><p>k-means是以最小化样本与质点平方误差作为目标函数，将每个簇的质点与簇内样本点的平方距离误差和称为畸变程度(distortions)，那么，对于一个簇，它的畸变程度越低，代表簇内成员越紧密，畸变程度越高，代表簇内结构越松散</p><p>畸变程度会随着类别的增加而降低，但对于有一定区分度的数据，在达到某个临界点时畸变程度会得到极大改善，之后缓慢下降，这个临界点就可以考虑为聚类性能较好的点</p><p> <img src="https://img-blog.csdnimg.cn/2020112518295967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>存在当曲线是单调递减的时仍然很难找出合适的簇数的可能</p><h4 id="轮廓系数（Silhouette-Coefficient）"><a href="#轮廓系数（Silhouette-Coefficient）" class="headerlink" title="轮廓系数（Silhouette Coefficient）"></a>轮廓系数（Silhouette Coefficient）</h4><p>轮廓系数是聚类结合和分离程序的评价指标，它基于两个因素来量化数据点适合其分配的簇的程度</p><ol><li><p>数据点与簇中其他点的距离有多近</p></li><li><p>数据点与其他簇中的点有多远</p></li></ol><p>计算距同一簇中所有数据点的平均距离<script type="math/tex">a_i</script><br>计算到最近的簇中所有数据点的平均距离<script type="math/tex">b_i</script></p><script type="math/tex; mode=display">\frac{b^{i}-a^{i}}{\max \left(a^{i}, b^{i}\right)}</script><p>轮廓系数值介于-1和1之间，越接近1表示样本所在簇合理</p><p>若近似为0，则说明样本在两个簇的边界上</p><p><img src="https://img-blog.csdnimg.cn/2020112518301011.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>如果簇是类圆形的，那么Kmeans算法是可以胜任的，它总是尝试在质心周围构造一个不错的球形</p><p>但这这意味着，当群集具有复杂的几何形状时，Kmeans的表现不好，如下<br><img src="https://img-blog.csdnimg.cn/20201125183024585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>不出所料，kmeans无法找出两个数据集的正确聚类</p><p>但是，如果我们使用核方法，将其转换为高维表示从而使数据线性可分离，则可以帮助kmeans完美地聚类此类数据集<br><img src="https://img-blog.csdnimg.cn/20201125183139392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding = utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeans</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,n_clusters, max_iters=<span class="number">100</span>, random_state=<span class="number">666</span>)</span>:</span></span><br><span class="line">        <span class="string">"""初始化Kmeans模型"""</span></span><br><span class="line">        self.n_clusters = n_clusters</span><br><span class="line">        self.max_iters = max_iters</span><br><span class="line">        self.random_state = random_state</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initializ_centroids</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        np.random.RandomState(self.random_state)</span><br><span class="line">        random_idx = np.random.permutation(X.shape[<span class="number">0</span>])</span><br><span class="line">        centroids = X[random_idx[:self.n_clusters]]</span><br><span class="line">        <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_centroids</span><span class="params">(self, X, labels)</span>:</span></span><br><span class="line">        centroids = np.zeros((self.n_clusters, X.shape[<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(self.n_clusters):</span><br><span class="line">            centroids[k, :] = np.mean(X[labels == k, :], axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_distance</span><span class="params">(self, X, centroids)</span>:</span></span><br><span class="line">        distance = np.zeros((X.shape[<span class="number">0</span>], self.n_clusters))</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(self.n_clusters):</span><br><span class="line">            row_norm = np.linalg.norm(X - centroids[k, :], axis=<span class="number">1</span>)</span><br><span class="line">            distance[:, k] = np.square(row_norm)</span><br><span class="line">        <span class="keyword">return</span> distance</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_closest_cluster</span><span class="params">(self, distance)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.argmin(distance, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_sse</span><span class="params">(self, X, labels, centroids)</span>:</span></span><br><span class="line">        distance = np.zeros(X.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(self.n_clusters):</span><br><span class="line">            distance[labels == k] = np.linalg.norm(X[labels == k] - centroids[k], axis=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> np.sum(np.square(distance))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        self.centroids = self.initializ_centroids(X)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iters):</span><br><span class="line">            old_centroids = self.centroids</span><br><span class="line">            distance = self.compute_distance(X, old_centroids)</span><br><span class="line">            self.labels = self.find_closest_cluster(distance)</span><br><span class="line">            self.centroids = self.compute_centroids(X, self.labels)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> np.all(old_centroids == self.centroids):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        self.error = self.compute_sse(X, self.labels, self.centroids)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X_predict)</span>:</span></span><br><span class="line">        distance = self.compute_distance(X, old_centroids)</span><br><span class="line">        <span class="keyword">return</span> self.find_closest_cluster(distance)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line">    <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">    features, true_labels = make_blobs(</span><br><span class="line">        n_samples=<span class="number">200</span>,</span><br><span class="line">        n_features=<span class="number">2</span>,</span><br><span class="line">        centers=<span class="number">3</span>,</span><br><span class="line">        cluster_std=<span class="number">2.75</span>,</span><br><span class="line">        random_state=<span class="number">42</span></span><br><span class="line">    )</span><br><span class="line">    scaler = StandardScaler()</span><br><span class="line">    scaled_features = scaler.fit_transform(features)</span><br><span class="line"></span><br><span class="line">    kmeans = KMeans(</span><br><span class="line">        n_clusters=<span class="number">3</span>,</span><br><span class="line">        max_iters=<span class="number">300</span>,</span><br><span class="line">        random_state=<span class="number">42</span></span><br><span class="line">    )</span><br><span class="line">    kmeans.fit(scaled_features)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>机器学习-周志华</p><p><a href="https://realpython.com/k-means-clustering-python/#writing-your-first-k-means-clustering-code-in-python" target="_blank" rel="noopener">K-Means Clustering in Python: A Practical Guide</a></p><p><a href="https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a" target="_blank" rel="noopener">K-means Clustering: Algorithm, Applications, Evaluation Methods, and Drawbacks</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;K-means聚类算法&quot;&gt;&lt;a href=&quot;#K-means聚类算法&quot; class=&quot;headerlink&quot; title=&quot;K-means聚类算法&quot;&gt;&lt;/a&gt;K-means聚类算法&lt;/h1&gt;&lt;h2 id=&quot;聚类&quot;&gt;&lt;a href=&quot;#聚类&quot; class=&quot;head
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="Algorithms" scheme="http://yoursite.com/tags/Algorithms/"/>
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
      <category term="KMeans" scheme="http://yoursite.com/tags/KMeans/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy豆瓣搜索页爬虫</title>
    <link href="http://yoursite.com/2020/11/23/Scrapy%E8%B1%86%E7%93%A3%E6%90%9C%E7%B4%A2%E9%A1%B5%E7%88%AC%E8%99%AB/"/>
    <id>http://yoursite.com/2020/11/23/Scrapy%E8%B1%86%E7%93%A3%E6%90%9C%E7%B4%A2%E9%A1%B5%E7%88%AC%E8%99%AB/</id>
    <published>2020-11-23T10:07:22.000Z</published>
    <updated>2020-11-23T10:07:20.812Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Scrapy-豆瓣搜索页爬虫"><a href="#Scrapy-豆瓣搜索页爬虫" class="headerlink" title="Scrapy 豆瓣搜索页爬虫"></a>Scrapy 豆瓣搜索页爬虫</h1><p>使用scrapy爬虫框架对豆瓣图书搜索结果进行爬取</p><h2 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h2><p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架</p><p>可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序</p><p>它提供了多种类型爬虫的基类，如BaseSpider、CrawlSpider等</p><h3 id="主要组件"><a href="#主要组件" class="headerlink" title="主要组件"></a>主要组件</h3><p>Scrapy框架主要由<strong>五大组件</strong>组成</p><ol><li><p><strong>调度器(Scheduler)</strong><br> 调度器，说白了把它假设成为一个URL的优先队列，由它来决定下一个要抓取的网址是什么，同时去除重复的网址，用户可以自己的需求定制调度器。</p></li><li><p><strong>下载器(Downloader)</strong><br> 下载器，是所有组件中负担最大的，它用于高速地下载网络上的资源<br> Scrapy的下载器代码不会太复杂，但效率高，主要的原因是Scrapy下载器是建立在twisted这个高效的        异步模型上的</p></li><li><p><strong>爬虫(Spider)</strong></p><p> 爬虫，是用户最关心的部份。用户定制自己的爬虫(通过定制正则表达式等语法)，用于从特定的网页中提取自己需要的信息，即所谓的实体(Item)。 用户也可以从中提取出链接,让Scrapy继续抓取下一个页面</p></li><li><p><strong>实体管道(Item Pipeline)</strong></p><p> 实体管道，用于处理爬虫(spider)提取的实体(Item)<br>主要的功能是持久化实体、验证实体的有效性、清除不需要的信息</p></li><li><p><strong>Scrapy引擎(Scrapy Engine)</strong></p><p> Scrapy引擎是整个框架的核心<br> 它用来控制调试器、下载器、爬虫。实际上，引擎相当于计算机的CPU,它控制着整个流程</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20201123180151632.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h3 id="数据流-Data-flow"><a href="#数据流-Data-flow" class="headerlink" title="数据流(Data flow)"></a>数据流(Data flow)</h3><p>Scrapy中的数据流由执行引擎控制，其过程如下:</p><ol><li>引擎打开一个网站，找到处理该网站的Spider并向该spider请求第一个要爬取的URL(s)</li><li>引擎从Spider中获取到第一个要爬取的URL并在调度器(Scheduler)以Request调度</li><li>引擎向调度器请求下一个要爬取的URL</li><li>调度器返回下一个要爬取的URL给引擎，引擎将URL通过下载中间件(request方向)转发给下载器(Downloader)</li><li>一旦页面下载完毕，下载器生成一个该页面的Response，并将其通过下载中间件(response方向)发送给引擎</li><li>引擎从下载器中接收到Response并通过Spider中间件(输入方向)发送给Spider处理</li><li>Spider处理Response并返回爬取到的Item及(跟进的)新的Request给引擎</li><li>引擎将(Spider返回的)爬取到的Item给Item Pipeline，将(Spider返回的)Request给调度器</li><li>(从第二步)重复直到调度器中没有更多地request，引擎关闭该网站</li></ol><h3 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h3><blockquote><p>创建项目    <code>scrapy startproject xxx</code><br>创建爬虫    <code>scrapy genspider xxx（爬虫名） xxx.com （爬取域）</code><br>生成文件    <code>scrapy crawl xxx -o xxx.json (生成json/csv文件)</code><br>运行爬虫    <code>scrapy crawl XXX</code><br>列出所有爬虫    <code>scrapy list</code></p></blockquote><h3 id="scrapy项目目录结构"><a href="#scrapy项目目录结构" class="headerlink" title="scrapy项目目录结构"></a>scrapy项目目录结构</h3><p>通过命令<code>scrapy startproject tutorial</code>创建一个新的项目<code>tutorial</code></p><p>将会创建包含下列内容的 <code>tutorial</code> 目录</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tutorial/</span><br><span class="line">    scrapy.cfg    <span class="comment"># 项目的配置文件</span></span><br><span class="line">    tutorial/<span class="comment"># 该项目的python模块之后将在此加入代码</span></span><br><span class="line">        __init__.py</span><br><span class="line">        items.py<span class="comment"># 项目中的item文件</span></span><br><span class="line">        pipelines.py<span class="comment"># 项目中的pipelines文件</span></span><br><span class="line">        settings.py<span class="comment"># 项目的设置文件</span></span><br><span class="line">        spiders/<span class="comment"># 放置spider代码的目录</span></span><br><span class="line">            __init__.py</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure><h2 id="使用scrapy爬取豆瓣搜索页"><a href="#使用scrapy爬取豆瓣搜索页" class="headerlink" title="使用scrapy爬取豆瓣搜索页"></a>使用scrapy爬取豆瓣搜索页</h2><p><strong>分析</strong></p><p><code>https://search.douban.com/movie/subject_search?search_text={search_text}&amp;cat=1002&amp;start={start}</code></p><p>search_text 搜索关键字</p><p>cat 搜索类别</p><p>start 开始的条数</p><p>url规则可以适用到图书电影搜索页面，后面的爬取也一样</p><p><strong>爬取后发现页面信息都无法获取</strong>，但是可以找到有个<code>window.__DATA__</code>猜测数据都被加密成了这串字符串<br><img src="https://img-blog.csdnimg.cn/20201123180017804.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>一轮百度发现有大佬把加密的js代码提取出来了！</p><p>于是直接给出大佬的链接<a href="https://mp.weixin.qq.com/s/2mpu_oY2-M0wcLvf1eU7Sw" target="_blank" rel="noopener">豆瓣读书搜索页的window.<strong>DATA</strong>的解密</a></p><p>解决了这个问题其他的就很好爬取了</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>完整代码见<a href="https://github.com/MorreInfo/MoreInfo_Crawler/blob/master/moreinfo_crawler/spiders/douban_book_search.py" target="_blank" rel="noopener">github仓库</a></p><p>提取出的js在<code>third_party/main.js</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanBookSearchSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'douban_book_search'</span></span><br><span class="line">    allowed_domains = [<span class="string">'douban.com'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,keyword=None,start=None,*args, **kwargs)</span>:</span></span><br><span class="line">        super(DoubanBookSearchSpider, self).__init__(*args, **kwargs)</span><br><span class="line">        self.keyword = keyword</span><br><span class="line">        self.start = start</span><br><span class="line">        self.start_urls.append(<span class="string">f'https://search.douban.com/book/subject_search?search_text=<span class="subst">&#123;self.keyword&#125;</span>&amp;cat=1001&amp;start=<span class="subst">&#123;self.start&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        r = re.search(<span class="string">'window.__DATA__ = "([^"]+)"'</span>, response.text).group(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 导入js</span></span><br><span class="line">        file_path = pathlib.Path.cwd() / <span class="string">'third_party/main.js'</span></span><br><span class="line">        <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>, encoding=<span class="string">'gbk'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            decrypt_js = f.read()</span><br><span class="line">        ctx = execjs.compile(decrypt_js)</span><br><span class="line">        data = ctx.call(<span class="string">'decrypt'</span>, r)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> data[<span class="string">'payload'</span>][<span class="string">'items'</span>]:</span><br><span class="line">            <span class="keyword">if</span> item.get(<span class="string">'rating'</span>, <span class="literal">None</span>):</span><br><span class="line">                cover_url = item[<span class="string">'cover_url'</span>]</span><br><span class="line">                score = item[<span class="string">'rating'</span>][<span class="string">'value'</span>]</span><br><span class="line">                score_num = item[<span class="string">'rating'</span>][<span class="string">'count'</span>]</span><br><span class="line">                url = item[<span class="string">'url'</span>]</span><br><span class="line">                abstract = item[<span class="string">'abstract'</span>]</span><br><span class="line">                title = item[<span class="string">'title'</span>]</span><br><span class="line">                id = item[<span class="string">'id'</span>]</span><br><span class="line">                <span class="keyword">yield</span> DouBanBookSearchItem(</span><br><span class="line">                    cover_url=cover_url,</span><br><span class="line">                    score=score,</span><br><span class="line">                    score_num=score_num,</span><br><span class="line">                    url=url,</span><br><span class="line">                    abstract=abstract,</span><br><span class="line">                    title=title,</span><br><span class="line">                    id=id)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.jianshu.com/p/cecb29c04cd2" target="_blank" rel="noopener">爬虫框架Scrapy个人总结（详细）熟悉</a></p><p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/architecture.html" target="_blank" rel="noopener">架构概览</a></p><p><a href="https://blog.csdn.net/ck784101777/article/details/104468780/" target="_blank" rel="noopener">Scrapy爬虫框架，入门案例（非常详细）</a></p><p><a href="https://mp.weixin.qq.com/s/2mpu_oY2-M0wcLvf1eU7Sw" target="_blank" rel="noopener">豆瓣读书搜索页的window.<strong>DATA</strong>的解密</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Scrapy-豆瓣搜索页爬虫&quot;&gt;&lt;a href=&quot;#Scrapy-豆瓣搜索页爬虫&quot; class=&quot;headerlink&quot; title=&quot;Scrapy 豆瓣搜索页爬虫&quot;&gt;&lt;/a&gt;Scrapy 豆瓣搜索页爬虫&lt;/h1&gt;&lt;p&gt;使用scrapy爬虫框架对豆瓣图书搜索结果进
      
    
    </summary>
    
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="crawler" scheme="http://yoursite.com/tags/crawler/"/>
    
      <category term="Scrapy" scheme="http://yoursite.com/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>使用crontab完成定时任务</title>
    <link href="http://yoursite.com/2020/11/23/%E4%BD%BF%E7%94%A8crontab%E5%AE%8C%E6%88%90%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <id>http://yoursite.com/2020/11/23/%E4%BD%BF%E7%94%A8crontab%E5%AE%8C%E6%88%90%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</id>
    <published>2020-11-22T17:34:39.000Z</published>
    <updated>2020-11-22T17:34:11.383Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用crontab完成定时任务"><a href="#使用crontab完成定时任务" class="headerlink" title="使用crontab完成定时任务"></a>使用crontab完成定时任务</h1><p>crond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务</p><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">usage:  crontab [-u user] file</span><br><span class="line">        crontab [-u user] [ -e | -l | -r ]</span><br><span class="line">        -e      (执行文字编辑器来设定时程表，内定的文字编辑器是 vi)</span><br><span class="line">        -l      (列出user的时间表)</span><br><span class="line">        -r      (删除user的时间表)</span><br></pre></td></tr></table></figure><p>root用户的任务调度操作可以通过<code>crontab –u root –e</code>来设置，也可以将调度任务直接写入<code>/etc/crontab</code>文件</p><h2 id="cron表达式"><a href="#cron表达式" class="headerlink" title="cron表达式"></a>cron表达式</h2><p>cron表达式是一个字符串，包含五个到七个由空格分隔的字段，表示一组时间，通常作为执行某个程序的时间表</p><p>minute  hour  day  month  week  command</p><p>minute： 表示分钟，可以是从0到59之间的任何整数</p><p>hour：表示小时，可以是从0到23之间的任何整数</p><p>day：表示日期，可以是从1到31之间的任何整数</p><p>month：表示月份，可以是从1到12之间的任何整数</p><p>week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日</p><p>command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">*    *    *    *    * <span class="built_in">command</span></span><br><span class="line">-    -    -    -    -</span><br><span class="line">|    |    |    |    |</span><br><span class="line">|    |    |    |    +----- 星期中星期几 (0 - 7) (星期天 为0)</span><br><span class="line">|    |    |    +---------- 月份 (1 - 12) </span><br><span class="line">|    |    +--------------- 一个月中的第几天 (1 - 31)</span><br><span class="line">|    +-------------------- 小时 (0 - 23)</span><br><span class="line">+------------------------- 分钟 (0 - 59)</span><br></pre></td></tr></table></figure><p>星号（*):代表所有可能的值，如month字段为星号，则表示每月都执行该命令操作</p><p>逗号（,):可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”</p><p>中杠（-):可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”</p><p>正斜线（/):可以用正斜线指定时间的间隔频率，例如“*/2”表示每两小时执行一次</p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><ol><li>每一分钟执行一次 /bin/ls</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* * * * * /bin/ls</span><br></pre></td></tr></table></figure><ol><li>在 12 月内, 每天的早上 6 点到 12 点，每隔 3 个小时 0 分钟执行一次 <code>/usr/bin/backup</code></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 6-12/3 * 12 * /usr/bin/backup</span><br></pre></td></tr></table></figure><ol><li>每天22：50关闭ssh服务</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">50 22 * * * /sbin/service sshd stop</span><br></pre></td></tr></table></figure><ol><li>在 <code>/etc/crontab</code> 中添加环境变量，在可执行命令之前添加命令 <code>. /etc/profile;/bin/sh</code>，使得环境变量生效</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">20 03 * * * . /etc/profile;/bin/sh test.sh</span><br></pre></td></tr></table></figure><h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h2><ol><li>crontab有2种编辑方式：直接编辑/etc/crontab文件与crontab –e，其中/etc/crontab里的计划任务是系统中的计划任务，而用户的计划任务需要通过crontab –e来编辑</li><li>crontab中的command尽量使用绝对路径，否则会经常因为路径错误导致任务无法执行</li><li>新创建的 cron 任务不会马上执行，至少要过 2 分钟后才可以，可以重启 cron 来马上执行</li><li>%在crontab文件中表示换行，因此假如脚本或命令含有%,需要使用\%来进行转义</li></ol><h3 id="Mac-下使用crontab遇到的问题"><a href="#Mac-下使用crontab遇到的问题" class="headerlink" title="Mac 下使用crontab遇到的问题"></a>Mac 下使用crontab遇到的问题</h3><p>我有一个Python爬虫脚本，在命令行时可以正常工作，但在crontab下报错</p><p><strong>can’t open file …  [Errno 1] Operation not permitted</strong></p><p>cron表达式如下</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">30</span> <span class="number">7</span> * * * /usr/local/bin/python3 script.py &gt;&gt; script.log <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure><p>尝试了许多不同的方法，包括尝试过赋予文件权限，以root用户身份创建cron作业，不同的Python路径，都不能正常运行</p><p>最后在Stack Overflow找到解决方案</p><p>赋予<code>cron</code>全磁盘访问权限，方法如下</p><ol><li>系统偏好设置-&gt;安全和隐私-&gt;完整磁盘访问</li><li><p>解除锁定以允许更改</p></li><li><p>单击 +</p></li><li>单击Command + Shift + G输入<code>/ usr / sbin</code></li><li>找到<code>cron</code> 添加</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.runoob.com/linux/linux-comm-crontab.html" target="_blank" rel="noopener">Linux crontab 命令</a></p><p><a href="https://www.linuxprobe.com/how-to-crontab.html" target="_blank" rel="noopener">crontab用法与实例</a></p><p><a href="https://www.cnblogs.com/ftl1012/p/crontab.html" target="_blank" rel="noopener">Linux crontab命令详解</a></p><p><a href="https://stackoverflow.com/questions/58844669/trying-to-run-a-python-script-with-cron-getting-errno-1-operation-not-permitt/62152555#62152555" target="_blank" rel="noopener">Trying to run a Python script with cron  Operation not permitted</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用crontab完成定时任务&quot;&gt;&lt;a href=&quot;#使用crontab完成定时任务&quot; class=&quot;headerlink&quot; title=&quot;使用crontab完成定时任务&quot;&gt;&lt;/a&gt;使用crontab完成定时任务&lt;/h1&gt;&lt;p&gt;crond是linux下用来周期性的
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>A Dynamic Directed Graph Convolutional Network for Action Recognition(DDGCN)</title>
    <link href="http://yoursite.com/2020/11/17/DDGCN%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/11/17/DDGCN%E7%AC%94%E8%AE%B0/</id>
    <published>2020-11-17T13:12:35.000Z</published>
    <updated>2020-11-17T15:53:03.180Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DDGCN-A-Dynamic-Directed-Graph-Convolutional-Network-for-Action-Recognition"><a href="#DDGCN-A-Dynamic-Directed-Graph-Convolutional-Network-for-Action-Recognition" class="headerlink" title="DDGCN: A Dynamic Directed Graph Convolutional Network for Action Recognition"></a>DDGCN: A Dynamic Directed Graph Convolutional Network for Action Recognition</h1><blockquote><p>作者 | Matthew Korban, Xin Li<br>单位 | 路易斯安那州立大学<br>论文地址 | <a href="https://link.zhihu.com/?target=https%3A//www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650749.pdf" target="_blank" rel="noopener">https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650749.pdf</a><br>会议 | ECCV 2020</p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>提出了一种动态有向图卷积网络(DDGCN)，从人体行为的骨架表示出发，对人体行为的时空特征进行建模</p><p>DDGCN由三个新的特征建模模块组成：</p><ol><li>动态卷积采样(DCS)</li><li>动态卷积权重(DCW)</li><li>有向图时空(DGST)特征提取</li></ol><p>DCS和DCW模块可以有效地捕捉动态的非相邻关节之间的时空相关性</p><p>DSTG特征提取模块，通过包含时空的有序信息来增强动作的特征</p><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构<img src="https://img-blog.csdnimg.cn/20201117212723550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></h2><h2 id="动态卷积采样-DCS"><a href="#动态卷积采样-DCS" class="headerlink" title="动态卷积采样(DCS)"></a>动态卷积采样(DCS)</h2><p>人体非相邻的子部分在人类行为中往往是相互关联的，且这种关联是动态的<br><img src="https://img-blog.csdnimg.cn/20201117212757212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>DCS算法可以总结如下</p><ol><li><p>按照骨架模板初始化静态图<script type="math/tex">G_S</script>，并相应地初始化所有节点的索引</p></li><li><p>初始化邻居采样：对于∀vi∈GS，分两步创建其初始有序近邻集合pi(B(Vi))</p><ul><li>创建包括图中所有其他节点的有序节点集合Oi，该有序节点集合Oi包括根据图到vi的图距离排序的图中的所有其他节点。 当两个节点Vj和Vr具有相同的图距离(例如，都离Vi有r跳距离)时，则根据它们的初始化索引对它们进行排序</li><li>给定核大小r，从Oi中选取前r个节点，这些节点在此步骤pi(B(Vi))中形成有序的邻集</li></ul></li><li><p>更新采样邻域：∀vi，通过学习减少识别损失的最优偏移量∆pi来更新索引偏移量和邻域采样</p></li></ol><p>最后，在<script type="math/tex">G_{ST}</script>上，通过如下公式(1)的图形卷积计算特征图<script type="math/tex">f_{ST}</script></p><script type="math/tex; mode=display">f_{S T}\left(v_{i}\right)=\sum_{v_{j} \in B\left(v_{i}\right)} w\left(v_{i}\right) \cdot\left(p_{i}\left(v_{j}\right)+\Delta p_{i}\left(v_{j}\right)\right)</script><p>其中i和j分别是中心采样节点和相邻采样节点的索引，B是动态相邻采样节点集合，w是动态权重函数，pi是动态相邻采样函数，∆pi是偏移采样函数</p><h2 id="动态卷积权重-DCW"><a href="#动态卷积权重-DCW" class="headerlink" title="动态卷积权重(DCW)"></a>动态卷积权重(DCW)</h2><p>DCW权重分配模块动态地将权重<script type="math/tex">w_i</script>分配给<script type="math/tex">v_i</script>的相邻节点</p><p>使用动态时间规整(DTW)算法来计算 <script type="math/tex">P_v=DTW_{path} (W,B(v))</script></p><p>其中<script type="math/tex">P_v</script>中的第一列定义了W中元素的排序索引，第二列表示所选元素及其在<script type="math/tex">B(V)</script>中的顺序</p><p><img src="https://img-blog.csdnimg.cn/20201117212842409.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h2 id="有向时空图特征-DSTG"><a href="#有向时空图特征-DSTG" class="headerlink" title="有向时空图特征(DSTG)"></a>有向时空图特征(DSTG)</h2><p><img src="https://img-blog.csdnimg.cn/20201117212858577.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>骨骼特征 <script type="math/tex">f_{i}^{B}=\overline{f_{i-1} f_{i}}=f_{i-1}-f_{i}</script></p><p>时间特征 <script type="math/tex">f_{i}^{T}=f_{i}^{t}-f_{i}^{t-1}</script></p><p>串联得到节点v<em>i的特征向量 $$F</em>{i}=\left{f<em>{i}^{J}, f</em>{i}^{B}, f_{i}^{T}\right}$$</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>在NTURGB-D 60和Kinetics数据集上性能均优于其他方法<br><img src="https://img-blog.csdnimg.cn/20201117213008955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p>DSTG模块对于性能提升最大，完整的DDC模块可得到最高的准确率</p><p><img src="https://img-blog.csdnimg.cn/20201117212959696.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h3 id="识别不完整的动作"><a href="#识别不完整的动作" class="headerlink" title="识别不完整的动作"></a>识别不完整的动作</h3><p>对丢失帧的动作识别进行的实验，分为以下3中情况</p><ul><li><p>运动开始时丢失帧</p></li><li><p>运动结束时丢失帧</p></li><li><p>序列中随机丢失的帧</p></li></ul><p>结论是<strong>运动开始时的序列存在大部分特征</strong><br><img src="https://img-blog.csdnimg.cn/20201117213022474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyODE1ODA3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>提出了一种基于骨架图的动态有向图卷积网络(DDGCN)动作识别算法</p><p>DDGCN由三个新模块组成，动态卷积抽样(DCS)、动态卷积权重分配(DCW)和有向图时空(DGST)特征提取</p><p>这些新模块有助于更好地捕捉时空依赖关系，骨架的层次结构和时序特征。 实验表明，DDGCN在多个公共数据集上的动作识别准确率优于最先进的算法</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;DDGCN-A-Dynamic-Directed-Graph-Convolutional-Network-for-Action-Recognition&quot;&gt;&lt;a href=&quot;#DDGCN-A-Dynamic-Directed-Graph-Convolutional-
      
    
    </summary>
    
    
      <category term="Paper" scheme="http://yoursite.com/categories/Paper/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
      <category term="ActionRecognition" scheme="http://yoursite.com/tags/ActionRecognition/"/>
    
  </entry>
  
  <entry>
    <title>支持向量机(SVM)</title>
    <link href="http://yoursite.com/2020/11/06/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA(SVM)/"/>
    <id>http://yoursite.com/2020/11/06/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA(SVM)/</id>
    <published>2020-11-06T08:39:23.000Z</published>
    <updated>2020-11-06T08:40:10.348Z</updated>
    
    <content type="html"><![CDATA[<h1 id="支持向量机（SVM）"><a href="#支持向量机（SVM）" class="headerlink" title="支持向量机（SVM）"></a>支持向量机（SVM）</h1><p>支持向量机（support vector machines, SVM）是一种二分类模型，它的基本模型是定义在特征空间上的<strong>间隔最大的线性分类器</strong></p><p>SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题</p><ul><li><p>优点:泛化错误率低，计算开销不大，结果易解释</p></li><li><p>缺点:对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二类问题</p></li></ul><h2 id="分隔超平面"><a href="#分隔超平面" class="headerlink" title="分隔超平面"></a>分隔超平面</h2><p><img src="https://github.com/benull/Resource/raw/master/svm1.png" alt="pic1"></p><p>上面将数据集分隔开来的直线称为分隔超平面 ( separating hyperplane)</p><p>在上面给出的例子中，由于数据点都在二维平面上，所 以此时分隔超平面就只是一条直线。但是，如果所给的数据集是三的，那么此时用来分隔数据的就是一个平面</p><p>显而易见，更高维的情况可以依此类推。如果数据集是1024维的，那么就需要一个1023维的对象来对数据进行分隔，该对象被称之为超平面(hyperplane)，也就是分类的决策边界</p><p>分布在超平面一侧的所有数据都属于某个类别，而分布在另一侧的所有数据则属于另一个类别</p><h2 id="线性可划分"><a href="#线性可划分" class="headerlink" title="线性可划分"></a>线性可划分</h2><p>存在一个划分超平面能将训练样本正确分类</p><p>而现实人物中，原始样本空间内也许并不在一个能正确划分两类样本的超平面，如下图</p><p><img src="https://github.com/benull/Resource/raw/master/svm2.png" alt="pic1"></p><p>对这样的问题, 可将样本从原始空间映射到一个更高维的特征空间, 使得样本在这个特征空间内线性可分</p><p>例如在上图中， 若将原始的二维空间映射到一个合适的三维空间, 就能找到一个合适的划分超平面</p><p>比如想要将下图的红点和蓝点变成线性可分的，那么就将映射<script type="math/tex">y = x</script>变成映射<script type="math/tex">y=x^2</script>，这样就线性可分了</p><p><img src="https://img-blog.csdnimg.cn/20190303081111808.png" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/20190303081101648.png" alt="在这里插入图片描述"></p><h2 id="间隔-margin"><a href="#间隔-margin" class="headerlink" title="间隔(margin)"></a>间隔(margin)</h2><p>对于任意一个超平面，其两侧数据点都距离它有一个最小距离（垂直距离），这两个最小距离的和就是间隔margin</p><p><img src="https://img-blog.csdnimg.cn/20190302091934374.png" alt="img"></p><h2 id="Hard-Margin-SVM"><a href="#Hard-Margin-SVM" class="headerlink" title="Hard Margin SVM"></a>Hard Margin SVM</h2><blockquote><p>当训练数据线性可分时，通过硬间隔最大化，学习一个线性的分类器，即线性可分支持向量机</p></blockquote><p><strong>svm尝试寻找一个最优决策边界，距离两个类别最近的样本距离最远</strong></p><p><img src="https://github.com/benull/Resource/raw/master/svm3.png" alt="pic1"></p><p>在样本空间中，划分超平面可用如下线性方程来描述：</p><script type="math/tex; mode=display">w^Tx+b=0</script><p>其中 <script type="math/tex">\boldsymbol{w}=\left(w_{1} ; w_{2} ; \ldots ; w_{d}\right)</script> 为法向量, 决定了超平面的方向; <script type="math/tex">b</script> 为位移项, 决定了超平面与原点之间的距离</p><p>样本空间中任意点 <script type="math/tex">\boldsymbol{x}</script> 到超平面 <script type="math/tex">(\boldsymbol{w}, b)</script> 的距离可写为</p><script type="math/tex; mode=display">r=\frac{\left|\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right|}{\|\boldsymbol{w}\|}</script><p>假设超平面 <script type="math/tex">(\boldsymbol{w}, b)</script> 能将训练样本正确分类, 即对于 <script type="math/tex">\left(\boldsymbol{x}_{i}, y_{i}\right) \in D,</script> 若 <script type="math/tex">y_{i}=</script> <script type="math/tex">+1,</script> 则有 <script type="math/tex">\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b>0 ;</script> 若 <script type="math/tex">y_{i}=-1,</script> 则有 <script type="math/tex">\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b<0 .</script> 令</p><script type="math/tex; mode=display">\left\{\begin{array}{ll}\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b \geqslant+1, & y_{i}=+1 \\\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b \leqslant-1, & y_{i}=-1\end{array}\right.</script><p>如上图所示, 距离超平面最近的这几个训练样本点使上式的等号成立, 它们被称为<strong>“支持向量”(support vector)</strong>, 两个异类支持向量到超平面的距离之和为</p><script type="math/tex; mode=display">\gamma=\frac{2}{\|\boldsymbol{w}\|}</script><p>显然, 为了最大化间隔, 仅需最大化 <script type="math/tex">\|\boldsymbol{w}\|^{-1},</script> 这等价于最小化 <script type="math/tex">\|\boldsymbol{w}\|^{2}</script></p><script type="math/tex; mode=display">\begin{array}{l}\min _{\boldsymbol{w}, b} \frac{1}{2}\|\boldsymbol{w}\|^{2} \\\text { s.t. } y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b\right) \geqslant 1, \quad i=1,2, \ldots, m\end{array}</script><p>这就是支持向量机(Support Vector Machine, 简称 SVM)的基本型</p><h2 id="Soft-Margin-SVM"><a href="#Soft-Margin-SVM" class="headerlink" title="Soft Margin SVM"></a>Soft Margin SVM</h2><blockquote><p>当训练数据近似线性可分时，通过软间隔最大化，学习一个线性支持向量机，又称为软间隔支持向量机</p></blockquote><p>前面我们是假定所有的训练样本在样本空间或特征空间中是严格线性可分的，即存在一个超平面能把不同类的样本完全分开，然而现实任务中很难确定这样的超平面（不管是线性超平面还是经过核变换到高维空间的超平面），所以引入松弛变量，允许一些样本出错，但我们希望出错的样本越少越好，所以松弛变量也有限制</p><p>具体来说，前面介绍的支持向量机的形式要求所有样本满足约束，即所有的样本必须划分正确，这称为硬间隔，而软间隔则是允许某些样本不满足约束</p><script type="math/tex; mode=display">y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b\right) \geqslant 1</script><p>如下图红色圈出了不满足约束的样本<br><img src="https://github.com/benull/Resource/raw/master/svm4.png" alt="pic1"></p><p>当然, 在最大化间隔的同时, 不满足约束的样本应尽可能少. 于是, 优化目标可写为</p><script type="math/tex; mode=display">\min _{\boldsymbol{w}, b} \frac{1}{2}\|\boldsymbol{w}\|^{2}+C \sum_{i=1}^{m} \ell_{0 / 1}\left(y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b\right)-1\right)</script><p>其中 <script type="math/tex">C>0</script> 是一个常数, <script type="math/tex">\ell_{0 / 1}</script> 是“0/1损失函数”</p><script type="math/tex; mode=display">\ell_{0 / 1}(z)=\left\{\begin{array}{ll}1, & \text { if } z<0 \\0, & \text { otherwise }\end{array}\right.</script><p>引入“松他变量” (slack variables) <script type="math/tex">\xi_{i} \geqslant 0,</script> 可将上式重写为</p><script type="math/tex; mode=display">\min _{\boldsymbol{w}, b, \xi_{i}} \frac{1}{2}\|\boldsymbol{w}\|^{2}+C \sum_{i=1}^{m} \xi_{i}</script><h2 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h2><p>现在的目标函数是二次的，约束条件是线性的，所以它是一个凸二次规划问题</p><p>这个问题可以用现成的QP (Quadratic Programming) 优化包进行求解</p><p>此外，由于这个问题的特殊结构，还可以通过拉格朗日对偶性（Lagrange Duality）变换到对偶变量 (dual variable) 的优化问题，即通过求解与原问题等价的对偶问题（dual problem）得到原始问题的最优解，这就是线性可分条件下支持向量机的对偶算法</p><p>这样做的优点在于：</p><ul><li>一者对偶问题往往更容易求解</li><li>二者可以自然的引入核函数，进而推广到非线性分类问题</li></ul><p>具体来说, 对每条约束添加拉格朗日乘子 <script type="math/tex">\alpha_{i} \geqslant 0,</script> 则该问题的拉格朗日函数可写为</p><script type="math/tex; mode=display">L(\boldsymbol{w}, b, \boldsymbol{\alpha})=\frac{1}{2}\|\boldsymbol{w}\|^{2}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b\right)\right)</script><p>其中 <script type="math/tex">\alpha=\left(\alpha_{1} ; \alpha_{2} ; \ldots ; \alpha_{m}\right) .</script> 令 <script type="math/tex">L(\boldsymbol{w}, b, \boldsymbol{\alpha})</script> 对 <script type="math/tex">\boldsymbol{w}</script> 和 <script type="math/tex">b</script> 的偏导为零可得</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{w} &=\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i} \\0 &=\sum_{i=1}^{m} \alpha_{i} y_{i}\end{aligned}</script><p>即可将 <script type="math/tex">L(\boldsymbol{w}, b, \boldsymbol{\alpha})</script> 中的 <script type="math/tex">\boldsymbol{w}</script> 和 <script type="math/tex">b</script> 消去, 就得到的目标函数对偶问题</p><script type="math/tex; mode=display">\max _{\boldsymbol{\alpha}} \sum_{i=1}^{m} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j} \boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j}</script><h2 id="非线形SVM"><a href="#非线形SVM" class="headerlink" title="非线形SVM"></a>非线形SVM</h2><blockquote><p>当训练数据线性不可分时，通过使用核技巧(kernel trick)及软间隔最大化，学习非线形支持向量机</p></blockquote><h3 id="非线性SVM算法原理"><a href="#非线性SVM算法原理" class="headerlink" title="非线性SVM算法原理"></a>非线性SVM算法原理</h3><p>对于输入空间中的非线性分类问题，可以通过非线性变换将它转化为某个维特征空间中的线性分类问题，在高维特征空间中学习线性支持向量机</p><p>令 <script type="math/tex">\phi(x)</script> 表示将 <script type="math/tex">x</script> 映射后的特征向量, 于是, 在特征空间中划分超平面所对<br>应的模型可表示为</p><script type="math/tex; mode=display">f(\boldsymbol{x})=\boldsymbol{w}^{\mathrm{T}} \phi(\boldsymbol{x})+b</script><p>其中 <script type="math/tex">\boldsymbol{w}</script> 和 <script type="math/tex">b</script> 是模型参数，有</p><script type="math/tex; mode=display">\begin{array}{l}\min _{\boldsymbol{w}, b} \frac{1}{2}\|\boldsymbol{w}\|^{2} \\\text { s.t. } y_{i}\left(\boldsymbol{w}^{\mathrm{T}} \phi\left(\boldsymbol{x}_{i}\right)+b\right) \geqslant 1, \quad i=1,2, \ldots, m\end{array}</script><p>其对偶问题是</p><script type="math/tex; mode=display">\max _{\boldsymbol{\alpha}} \sum_{i=1}^{m} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j} \phi\left(\boldsymbol{x}_{i}\right)^{\mathrm{T}} \phi\left(\boldsymbol{x}_{j}\right)</script><script type="math/tex; mode=display">\begin{array}{ll}\text { s.t. } & \sum_{i=1}^{m} \alpha_{i} y_{i}=0 \\& \alpha_{i} \geqslant 0, \quad i=1,2, \ldots, m\end{array}</script><p>由于在线性支持向量机学习的对偶问题里，目标函数和分类决策函数都<strong>只涉及实例和实例之间的内积，所以不需要显式地指定非线性变换，而是用核函数替换当中的内积</strong></p><p>有了这样的函数，我们就不必直接去计算高维甚至无穷维特征空间中的内积，于是上式可重写为</p><script type="math/tex; mode=display">\begin{array}{ll}\max _{\boldsymbol{\alpha}} & \sum_{i=1}^{m} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j} \kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \\\text { s.t. } & \sum_{i=1}^{m} \alpha_{i} y_{i}=0 \\& \alpha_{i} \geqslant 0, \quad i=1,2, \ldots, m\end{array}</script><h3 id="常见的核函数"><a href="#常见的核函数" class="headerlink" title="常见的核函数"></a>常见的核函数</h3><script type="math/tex; mode=display">\begin{aligned}&\text { 线性核 } \quad \kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j}\\&\text { 多项式核 } \quad \kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\left(\boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j}\right)^{d} \quad d \geqslant 1 \text { 为多项式的次数 }\\&\text { 高斯核 } \quad \kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\exp \left(-\frac{\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|^{2}}{2 \sigma^{2}}\right) \quad \sigma>0 \text { 为高斯核的带宽(width) }\\&\text { 拉普拉斯核 } \quad \kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\exp \left(-\frac{\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|}{\sigma}\right) \quad \sigma>0\\&\text { Sigmoid 核 } \quad \kappa\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\tanh \left(\beta \boldsymbol{x}_{i}^{\mathrm{T}} \boldsymbol{x}_{j}+\theta\right) \quad \text { tanh 为双曲正切函数, } \beta>0, \theta<0\end{aligned}</script><h2 id="二分类扩展到多分类问题"><a href="#二分类扩展到多分类问题" class="headerlink" title="二分类扩展到多分类问题"></a>二分类扩展到多分类问题</h2><p>SVM 扩展可解决多个类别分类问题</p><p><strong>one-vs-rest</strong></p><p>对于每个类，有一个当前类和其他类的二类分类器（one-vs-rest）<br>将多分类问题转化为 n 个二分类问题</p><h2 id="svm解决回归问题"><a href="#svm解决回归问题" class="headerlink" title="svm解决回归问题"></a>svm解决回归问题</h2><p>现在我们来考虑回归问题，传统回归模型通常直接基于模型输出 <script type="math/tex">f(x)</script> 与真实输出 <script type="math/tex">y</script> 之 间的差别来计算损失, 当且仅当 <script type="math/tex">f(\boldsymbol{x})</script> 与 <script type="math/tex">y</script> 完全相同时, 损失才为零</p><p>与此不同 <script type="math/tex">,</script> <strong>支持向量回归(Support Vector Regression, 简称 SVR)</strong>假设我们能容忍 <script type="math/tex">f(x)</script> 与 <script type="math/tex">y</script> 之间最多有 <script type="math/tex">\epsilon</script> 的偏差, 即仅当 <script type="math/tex">f(\boldsymbol{x})</script> 与 <script type="math/tex">y</script> 之间的差别绝对值大于 <script type="math/tex">\epsilon</script> 时才计算损失</p><p>如图所示, 这相当于以 <script type="math/tex">f(x)</script> 为中心, 构建了一个宽度为 <script type="math/tex">2 \epsilon</script> 的间隔带, 若训练样本落入此间隔带, 则认为是被预测正确的</p><p><img src="https://github.com/benull/Resource/raw/master/svm5.png" alt="pic1"></p><p>于是, SVR 问题可形式化为</p><script type="math/tex; mode=display">\min _{\boldsymbol{w}, b} \frac{1}{2}\|\boldsymbol{w}\|^{2}+C \sum_{i=1}^{m} \ell_{c}\left(f\left(\boldsymbol{x}_{i}\right)-y_{i}\right)</script><p>其中 <script type="math/tex">C</script> 为正则化常数, <script type="math/tex">\ell_{\epsilon}</script> 是图 6.7 所示的 <script type="math/tex">\epsilon</script> -不敏感损失 <script type="math/tex">(\epsilon</script> -insensitive loss <script type="math/tex">)</script> 函数</p><script type="math/tex; mode=display">\ell_{\epsilon}(z)=\left\{\begin{array}{ll}0, & \text { if }|z| \leqslant \epsilon \\|z|-\epsilon, & \text { otherwise }\end{array}\right.</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href>机器学习算法（一）SVM</a></p><p>机器学习-周志华</p><p><a href="https://zhuanlan.zhihu.com/p/31886934" target="_blank" rel="noopener">支持向量机（SVM）——原理篇</a></p><p>Machine Learning in Action by Peter Harrington</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;支持向量机（SVM）&quot;&gt;&lt;a href=&quot;#支持向量机（SVM）&quot; class=&quot;headerlink&quot; title=&quot;支持向量机（SVM）&quot;&gt;&lt;/a&gt;支持向量机（SVM）&lt;/h1&gt;&lt;p&gt;支持向量机（support vector machines, SVM）是一种
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="Algorithms" scheme="http://yoursite.com/tags/Algorithms/"/>
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>分类算法评估指标</title>
    <link href="http://yoursite.com/2020/11/05/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/"/>
    <id>http://yoursite.com/2020/11/05/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/</id>
    <published>2020-11-05T06:26:23.000Z</published>
    <updated>2020-11-05T06:26:03.282Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分类算法评估指标"><a href="#分类算法评估指标" class="headerlink" title="分类算法评估指标"></a>分类算法评估指标</h1><h2 id="精度（Accuracy）"><a href="#精度（Accuracy）" class="headerlink" title="精度（Accuracy）"></a>精度（Accuracy）</h2><p>即正确预测的正反例数 /预测总数</p><p>对于样例集D,分类错误率定义为</p><script type="math/tex; mode=display">E(f ; D)=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right) \neq y_{i}\right)</script><p>精度则定义为</p><script type="math/tex; mode=display">\begin{aligned}\operatorname{acc}(f ; D) &=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right)=y_{i}\right) \\&=1-E(f ; D)\end{aligned}</script><ul><li><p>对于样本类别数量严重不均衡的情况（skewed)不能用精度指标来衡量</p><p>例如：有A类1000个，B类5个，如果我把这1005个样本都预测成A类，正确率=1000/1005=99.5%</p></li><li><p>对于有倾向性的问题，往往不能用精度指标来衡量</p><p>例如：判断这个病人是不是病危，如果不是病危错误判断为病危，那只是损失一点医务人员的时间和精力，如果是把病危的人判断为非病危状态，那损失的就是一条人命</p></li></ul><p>对于以上两种情况，单纯根据Accuracy来衡量算法的优劣已经失效，这个时候就需要对目标变量的真实值和预测值做更深入的分析</p><h2 id="混淆矩阵（confusion-matrix）"><a href="#混淆矩阵（confusion-matrix）" class="headerlink" title="混淆矩阵（confusion matrix）"></a>混淆矩阵（confusion matrix）</h2><p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为</p><ul><li><p>真正例（True Positive)</p></li><li><p>假正例（False Positive)</p></li><li>真反例（True Negative）</li><li>假反例（False Negative）</li></ul><p>分类结果的混淆矩阵如下</p><div class="table-container"><table><thead><tr><th></th><th>预测值0</th><th>预测值1</th></tr></thead><tbody><tr><td>真实值0</td><td>TN</td><td>FP</td></tr><tr><td>真实值1</td><td>FN</td><td>TP</td></tr></tbody></table></div><h2 id="精准率（precision）"><a href="#精准率（precision）" class="headerlink" title="精准率（precision）"></a>精准率（precision）</h2><script type="math/tex; mode=display">\text {precision}=\frac{T P}{T P+F P}</script><p>精准率就是预测为正例的那些数据里预测正确的数据个数</p><h2 id="召回率（recall）"><a href="#召回率（recall）" class="headerlink" title="召回率（recall）"></a>召回率（recall）</h2><script type="math/tex; mode=display">\text {recall}=\frac{T P}{T P+F N}</script><p>召回率就是真实为正例的那些数据里预测正确的数据个数</p><p>精准率和查全率是一对矛盾的度量，一般来说，精准率高时，召回率则偏低；而召回率高时，精准率则偏低</p><h2 id="F1-Score"><a href="#F1-Score" class="headerlink" title="F1 Score"></a>F1 Score</h2><p>F1 Score同时关注精准率和召回率，是precision 和 recall 的调和平均值</p><p>它的值更接近于Precision与Recall中较小的值</p><script type="math/tex; mode=display">\frac{1}{F 1}=\frac{1}{2}\left(\frac{1}{\text {precision}}+\frac{1}{\text {recall}}\right)</script><script type="math/tex; mode=display">F 1=\frac{2 \cdot \text {precision } \cdot \text { recall}}{\text {precision }+\text {recall}}</script><h2 id="PR曲线"><a href="#PR曲线" class="headerlink" title="PR曲线"></a>PR曲线</h2><p>根据学习器的预测结果对样例进行排序, 排在前面的是学习器认为“最可能”是正例的样本, 排在最后的则是学习器认为“最 不可能”是正例的样本. 按此顺序逐个把样本作为正例进行预测, 则每次可以计算出当前的精准率、召回率</p><p>以精准率为纵轴、召回率为横轴作图, 就得到了精准率-召回率曲线, 简称“P-R曲线”，显示该曲线的图称为“P-R图”</p><p><img src="https://github.com/benull/Resource/raw/master/ev1.png" alt="ev1"></p><p>与ROC曲线左上凸效果好不同的是，PR曲线是右上凸效果越好</p><p>若一个学习器的P-R曲线被另一个学习器的曲线完全包住，则可断言后者的性能优于前者</p><h2 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h2><p>ROC(Receiver Operating Characteristic)受试者工作特性曲线</p><p>True Postitve Rate(真正例率)：正样本中被预测对比例</p><script type="math/tex; mode=display">\text {TPR}=\frac{TP}{TP+FN}</script><p>False Positive Rate(假正例率)：负样本被预测错的比例</p><script type="math/tex; mode=display">\text {FPR}=\frac{FP}{TN+FP}</script><p>ROC是一个以TPR为纵坐标，FPR为横坐标构造出来的一幅图</p><p><img src="https://github.com/benull/Resource/raw/master/ev2.png" alt="ev2"></p><p>在ROC空间，ROC曲线越凸向左上方向效果越好，因为这说明精确率高且覆盖率大</p><p>进行学习器的比较时, 与 P-R 图相似, 若一个学习器的 ROC 曲线被另一 个学习器的曲线完全“包住”, 则可断言后者的性能优于前者; 若两个学习器的 ROC 曲线发生交叉, 则难以一般性地断言两者熟优熟劣. 此时如果一定要进行比较, 则较为合理的判据是比较 ROC曲线下的面积, 即 AUC</p><h2 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h2><p>AUC（Area Under Curve）是一种模型分类指标，且仅仅是二分类模型的评价指标</p><p>AUC 值为 ROC 曲线所覆盖的区域面积，显然，AUC越大，分类器分类效果越好</p><p>AUC的物理意义正样本的预测结果大于负样本的预测结果的概率。所以AUC反应的是分类器对样本的排序能力。另外值得注意的是，AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价分类器性能的一个原因</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/36305931" target="_blank" rel="noopener">机器学习评估指标</a></p><p>机器学习-周志华</p><p><a href="https://blog.csdn.net/chocolate_chuqi/article/details/81162244" target="_blank" rel="noopener">回顾及总结—评价指标（分类指标)</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分类算法评估指标&quot;&gt;&lt;a href=&quot;#分类算法评估指标&quot; class=&quot;headerlink&quot; title=&quot;分类算法评估指标&quot;&gt;&lt;/a&gt;分类算法评估指标&lt;/h1&gt;&lt;h2 id=&quot;精度（Accuracy）&quot;&gt;&lt;a href=&quot;#精度（Accuracy）&quot; cla
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Fashion Image Retrieval Based on Regional Representation for Design Protection</title>
    <link href="http://yoursite.com/2020/11/03/PsNet/"/>
    <id>http://yoursite.com/2020/11/03/PsNet/</id>
    <published>2020-11-03T13:20:32.000Z</published>
    <updated>2020-11-04T16:24:33.842Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Which-Is-Plagiarism-Fashion-Image-Retrieval-Based-on-Regional-Representation-for-Design-Protection"><a href="#Which-Is-Plagiarism-Fashion-Image-Retrieval-Based-on-Regional-Representation-for-Design-Protection" class="headerlink" title="Which Is Plagiarism: Fashion Image Retrieval Based on Regional Representation for Design Protection"></a>Which Is Plagiarism: Fashion Image Retrieval Based on Regional Representation for Design Protection</h1><blockquote><p>作者 | Yining Lang, Yuan He, Fan Yang, Jianfeng Dong, Hui Xue</p><p>单位 | 阿里；浙江工商大学；AZFT</p><p>会议｜CVPR2020</p><p><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Lang_Which_Is_Plagiarism_Fashion_Image_Retrieval_Based_on_Regional_Representation_CVPR_2020_paper.pdf" target="_blank" rel="noopener">paper地址</a></p></blockquote><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在服装领域，虽然打假一直不断，但盗版抄袭问题依旧普遍存在，而且从线上线下，抄袭手段越来越刁钻。目前来看，服装领域的抄袭有以下三类</p><p>•<strong>图片盗用</strong></p><p>​    抄袭成本很低，很容易被平台的图片检索系统锁定</p><p>•<strong>创意盗版</strong>  </p><p>​    抄袭成本稍高，但基于相似度度量的算法，可以对它们进行召回和治理</p><p>•<strong>对服装的某些区域进行修改</strong></p><p>   抄袭成本高，需要人工审核发现，打假成本也高</p><p><img src="https://github.com/benull/Resource/raw/master/psnet1.png" alt="pic1"></p><blockquote><p>两组盗版示例，其中每组中左图为正版服装，右图为盗版服装</p></blockquote><h3 id="盗版服装检索的难点"><a href="#盗版服装检索的难点" class="headerlink" title="盗版服装检索的难点"></a>盗版服装检索的难点</h3><p>盗版服装的形式层出不穷，有些盗版服装跟原图比较相似，但是有些并不相似</p><p>而且有些盗版服装与原创服装属于不同的类型，提高了网络训练时的要求</p><p><img src="https://github.com/benull/Resource/raw/master/psnet2.png" alt="pic2"></p><h3 id="盗版服装的定义"><a href="#盗版服装的定义" class="headerlink" title="盗版服装的定义"></a>盗版服装的定义</h3><p>作为盗版服装检索领域的首次工作，作者对盗版服装的定义是整体上抄袭原版服装设计和风格，服装修改的局部区域数小于等于2</p><p><img src="https://github.com/benull/Resource/raw/master/psnet3.png" alt="pic3"></p><blockquote><p>将图像中的服装分为五个区域，包括领子、胸部、腰部和两个袖子区域</p></blockquote><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="基于三元组的损失函数（for-相似性检索）"><a href="#基于三元组的损失函数（for-相似性检索）" class="headerlink" title="基于三元组的损失函数（for 相似性检索）"></a>基于三元组的损失函数（for 相似性检索）</h3><script type="math/tex; mode=display">\begin{array}{c}\mathcal{L}_{t r i}\left(I, I^{+}, I^{-}\right)=\sum_{r=1}^{R} \max \left(D_{r}^{I, I^{+}}-D_{r}^{I, I^{-}}+m, 0\right) \\\mathcal{L}_{t r a}=\sum_{n=1}^{N} \mathcal{L}_{t r i}\left(I, I^{+}, I^{-}\right)\end{array}</script><h3 id="基于三元组的损失函数（for-盗版检索）"><a href="#基于三元组的损失函数（for-盗版检索）" class="headerlink" title="基于三元组的损失函数（for 盗版检索）"></a>基于三元组的损失函数（for 盗版检索）</h3><script type="math/tex; mode=display">\begin{array}{c}\mathcal{L}_{t r i}^{\prime}\left(I, I^{+}, I^{-}\right)=\sum_{r=1}^{R} \max \left(D_{r}^{I, I^{+}}-D_{r}^{I, I^{-}}+m, 0\right) \cdot \lambda_{r} \\\alpha_{t r i}=\frac{\operatorname{avg}\left\{\left\|f_{r}(I)-f_{r}\left(I^{+}\right)\right\|_{2} ; r=1,2, \ldots R\right\}}{\max \left\{\left\|f_{r}(I)-f_{r}\left(I^{+}\right)\right\|_{2} ; r=1,2, \ldots R\right\}} \\\mathcal{L}_{p l a}=\sum_{n=1}^{N}\left[\mathcal{L}_{t r i}^{\prime}\left(I, I^{+}, I^{-}\right) \cdot \alpha_{t r i}\right]\end{array}</script><h2 id="网络框架"><a href="#网络框架" class="headerlink" title="网络框架"></a>网络框架</h2><h3 id="PS-Net总体框架"><a href="#PS-Net总体框架" class="headerlink" title="PS-Net总体框架"></a>PS-Net总体框架</h3><p><img src="https://github.com/benull/Resource/raw/master/psnet4.png" alt="pic4"></p><h3 id="Network-Backbone"><a href="#Network-Backbone" class="headerlink" title="Network Backbone"></a>Network Backbone</h3><p><strong>HR-Net提取图片的特征</strong></p><p>​    HR-Net 的多分辨率子网并行连接，使得每一个高分辨率到低分辨率的表征都从其它并行表示中反复接受信息，从而得到丰富的高分辨率表征</p><p>​    但HR-Net不是必须的，可以用ResNet、VGG-Net 等替代</p><h3 id="Landmark-Branch"><a href="#Landmark-Branch" class="headerlink" title="Landmark Branch"></a>Landmark Branch</h3><p>关键点估计分支，为划分区域做准备，通过反卷积进行上采样</p><h3 id="Retrieval-Branch"><a href="#Retrieval-Branch" class="headerlink" title="Retrieval Branch"></a>Retrieval Branch</h3><p>聚合局部区域的特征进行检索</p><p>根据 Landmark Branch 得到的关键点预测和 输出的热力图，得到特定局部区域在特征图上的位置</p><p>再根据特定区域在特征图上的位置，通过ROI pooling得到 Retrieval Branch 的特征图中该区域相应的局部特征图</p><h3 id="Plagiarized-Fashion-数据集"><a href="#Plagiarized-Fashion-数据集" class="headerlink" title="Plagiarized Fashion 数据集"></a>Plagiarized Fashion 数据集</h3><p>•总共60,000张图片,其中40,000用于训练 20,000用于测试</p><p>•包括4类服装：短袖T恤、长袖上衣、外套以及连衣裙</p><p>•图片从淘宝网爬取并经过专家标注</p><p><img src="https://github.com/benull/Resource/raw/master/psnet5.png" alt="pic5"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>•提出了一个新的抄袭服装检索问题</p><p>•建立了新的用于抄袭服装检索的数据集Plagiarism  Fashion</p><p>•提出了一种基于区域表示的多任务网络PS-Net且达到了SOTA</p><p>•PS-Net还可以用于传统的服装检索和关键点估计任务</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Which-Is-Plagiarism-Fashion-Image-Retrieval-Based-on-Regional-Representation-for-Design-Protection&quot;&gt;&lt;a href=&quot;#Which-Is-Plagiarism-Fa
      
    
    </summary>
    
    
      <category term="Paper" scheme="http://yoursite.com/categories/Paper/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
      <category term="Retrieval" scheme="http://yoursite.com/tags/Retrieval/"/>
    
  </entry>
  
  <entry>
    <title>集成学习</title>
    <link href="http://yoursite.com/2020/10/30/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/10/30/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-10-30T05:01:23.000Z</published>
    <updated>2020-10-30T04:58:22.550Z</updated>
    
    <content type="html"><![CDATA[<h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><p>集成学习(ensemble learning)通过构建并结合多学习器来完成学习任务，常可获得比单一学习器显著优越的泛化性能</p><p>要获得好的集成，个体学习器应好而不同，即个体学习器要有一定的准确性，并且要有多样性，即学习器间要有差异</p><p>根据个体学习器的生成方式, 目前的集成学习方法大致可分为两大类</p><ul><li><p>学习器间存在强依赖关系、必须串行生成的序列化方法，如Boosting</p></li><li><p>学习器间不存在强依赖关系、可同时生成的并行化方法，如 Bagging 和随机森林</p></li></ul><p>集成学习在各个规模的数据集上都有很好的策略</p><ul><li><p>数据集大：划分成多个小数据集，学习多个模型进行组合</p></li><li><p>数据集小：利用Bootstrap方法(也称为自助法，一种有放回的抽样方法)进行抽样，得到多个数据集，分别训练多个模型再进行组合</p></li></ul><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>Boosting 是一族可将弱学习器提升为强学习器的算法</p><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><ol><li>先从初始训练集训练出一个基学习器</li><li>根据基学习器的表现对训练样本分布进行调整, 使得先前基学习器做错的训练样本在后续受到更多关注</li><li>基于调整后的样本分布来训练下一个基学习器;</li><li>重复进行, 直至基学习器数目达到事先指定的值 $T,$ 最终将这 $T$ 个基学习器进行加权结合</li></ol><p>从偏差-方差分解的角度看, Boosting 主要关注降低偏差, 因此 Boosting 能基于泛化性能相当弱的学习器构建出很强的集成</p><p>Boosting 族算法最著名的代表是 AdaBoost,是通过集中关注被已有分类器错分的那些数据来获得新的分类器</p><h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><ul><li>优点:泛化错误率低，易编码，可以应用在大部分分类器上</li><li>缺点:对离群点敏感</li></ul><h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><ol><li>训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量<em>D</em>，权重都初始化成相等值</li><li>在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器</li><li>在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本 的权重将会提高</li><li>计算出<em>D</em>之后，AdaBoost又开始进入下一轮迭代</li><li>AdaBoost算法会不断地重复训练和调整权重的过程，直到训练错误率为0或者弱分类器的数目达到用户的指定值为止</li></ol><p><img src="https://github.com/benull/Resource/raw/master/adaboost.png" alt="adaboost"></p><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>Bagging 是并行式集成学习方法最著名的代表</p><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><ol><li><p>给定包含 $m$ 个样本的数据集, 我们先随机取出一个样本放入采样集中, 再把该样本放回初始数据集, 使得下次采样时该样本仍有可能被选中</p></li><li><p>经过 $m$ 次随机采样操作, 我们得到含 $m$ 个样本的采样集, 初始训练集中有的样本在采样集里多次出现, 有的则从未出现</p></li><li><p>采样出 $T$ 个含 $m$ 个训练样本的采样集, 然后基于每个采样集训练出一个基学习器</p></li><li><p>将这些基学习器进行结合</p></li></ol><p>在对预测输出进行结合时, Bagging 通常对分类任务使用简单投票法, 对回归任务使用简单平均法</p><ul><li>Bagging通过降低基分类器的方差，改善了泛化误差</li><li>其性能依赖于基分类器的稳定性；如果基分类器不稳定，bagging有助于降低训练数据的随机波动导致的误差；如果稳定，则集成分类器的误差主要由基分类器的偏倚引起</li><li>由于每个样本被选中的概率相同，因此bagging并不侧重于训练数据集中的任何特定实例</li></ul><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林(Random Forest) 是 Bagging 的一个扩展变体</p><p>随即森林在以决策树为基学习器构建 Bagging 集成的基础上, 进一步在决策树的训练过程中引入了随机属性选择</p><p>具体来说, 传统决策树在选择划分属性时是在当前结点的属性集合(假定有 $d$ 个属性)中选择一个最优属性</p><p>而在随即森林中, 对基决策树的每个结点, 先从该结点的属性集合中随机选择一个包含 $k$个属性的子集, 然后再从这个子集中选择一个最优属性用于划分</p><p>随机森林的训练效率常优于 Bagging， 因为在个体决策树的构建过程中, Bagging 使用的是“确定型”决策树, 在选择划分属性时要对结点的所有属性进行考察,而随机森林使用的“随机型”决策树则只需考察一个属性子集</p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>具有极好的准确率</li><li>能够有效地运行在大数据集上</li><li>能够处理具有高维特征的输入样本，而且不需要降维</li><li>能够评估各个特征在分类问题上的重要性</li><li>对于缺省值问题也能够获得很好得结果</li></ul><h2 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h2><p>每个基学习器之间不存在很强的依赖性，为了提高集成的泛化能力在最终预测结果时，需要一定的策略对多个结果进行结合</p><h4 id="平均法"><a href="#平均法" class="headerlink" title="平均法"></a>平均法</h4><p>对数值型输出，最常见的结合策略是使用平均法，又可分为</p><ul><li>简单平均法</li><li>加权平均法</li></ul><p>一般而言，在个体学习器性能相差较大时宜使用加权平均法，而在个体学习器性能相近时宜使用简单平均法</p><h4 id="投票法"><a href="#投票法" class="headerlink" title="投票法"></a>投票法</h4><p>对分类任务来说, 学习器将从类别标记集合 中预测出一个标记, 最常见的结合策略是使用投票法</p><ul><li><p>绝对多数投票法</p><p>若某标记得票过半数，则预测为该标记；否则拒绝预测</p></li><li><p>相对多数投票法</p><p>预测为得票最多的标记。若同时有多个标记获得最高票，则从中随机选取一个。</p></li><li><p>加权投票法</p></li></ul><h4 id="学习法"><a href="#学习法" class="headerlink" title="学习法"></a>学习法</h4><p>当训练数据很多时, 一种更为强大的结合策略是使用“学习法”, 即通过另一个学习器来进行结合</p><p>Stacking 是学习法的典型代表</p><h5 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h5><p>Stacking是通过一个元分类器或者元回归器来整合多个分类模型或回归模型的集成学习技术</p><p>基础模型通常包含不同的学习算法,利用整个训练集做训练</p><p>元模型将基础模型的特征作为特征进行训练</p><p><img src="https://github.com/benull/Resource/raw/master/stacking.png" alt="stacking"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/zongfa/p/9304353.html" target="_blank" rel="noopener">机器学习—集成学习(Ensemble Learning)</a></p><p><a href="https://blog.csdn.net/zwqjoy/article/details/80431496" target="_blank" rel="noopener">集成学习—bagging、boosting、stacking</a></p><p>机器学习-周志华</p><p>Machine Learning in Action by Peter Harrington</p><p><a href="https://blog.csdn.net/yangyin007/article/details/82385967" target="_blank" rel="noopener">随机森林算法及其实现（Random Forest)</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;集成学习&quot;&gt;&lt;a href=&quot;#集成学习&quot; class=&quot;headerlink&quot; title=&quot;集成学习&quot;&gt;&lt;/a&gt;集成学习&lt;/h1&gt;&lt;p&gt;集成学习(ensemble learning)通过构建并结合多学习器来完成学习任务，常可获得比单一学习器显著优越的泛化性能&lt;
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="Algorithms" scheme="http://yoursite.com/tags/Algorithms/"/>
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
      <category term="集成学习" scheme="http://yoursite.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>决策树</title>
    <link href="http://yoursite.com/2020/10/28/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>http://yoursite.com/2020/10/28/%E5%86%B3%E7%AD%96%E6%A0%91/</id>
    <published>2020-10-28T15:20:29.000Z</published>
    <updated>2020-10-28T15:21:24.176Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树学习采用的是自顶向下的递归方法，其基本思想是以信息熵为度量构造一颗熵值下降最快的树，到叶子节点处，熵值为0</p><p>具有非常好的可解释性、分类速度快的优点，是一种有监督学习</p><p>最早提及决策树思想的是Quinlan在1986年提出的ID3算法和1993年提出的C4.5算法，以及Breiman等人在1984年提出的CART算法</p><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>一般的，一颗决策树包含一个根结点、若干个内部节点和若干个叶节点</p><h3 id="构造"><a href="#构造" class="headerlink" title="构造"></a>构造</h3><p>构造就是生成一棵完整的决策树。简单来说，构造的过程就是选择什么属性作为节点的过程</p><p>叶结点对应于决策结果, 其他每个结点则对应于一个属性测试，每个结点包含的样本集合根据属性测试的结果被划分到子结点中; </p><p>根结点包含样本全集，从根结点到每个叶结点的路径对应了一个判定测试序列. 决策树学习的目的是为了产生一棵泛化能力强, 即处理未见示例能力强的决策树，其基本流程遵循简单且直观的分而治之策略</p><p>显然, 决策树的生成是一个递归过程. 在决策树基本算法中, 有三种情形会导致递归返回:</p><ol><li>当前结点包含的样本全属于同一类别, 无需划分</li><li>当前属性集为空, 或是所有样本在所有属性上取值相同, 无法划分</li><li>当前结点包含的样本集合为空, 不能划分</li></ol><h3 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h3><p>决策树学习的关键是如何选择最优划分属性</p><p>随着划分过程不断进行, 我们希望决策树的分支结点所包含的样本尽可能属于同一类别, 即结点的“纯度”越来越高</p><h4 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h4><p>信息熵在信息论中代表随机变量不确定度的度量</p><p>熵越大，数据的不确定性越高，纯度越低</p><p>熵越小，数据的不确定性越低，纯度越高</p><p>假定当前样本集合 <script type="math/tex">D</script> 中第 <script type="math/tex">k</script> 类样本所占的比例为 <script type="math/tex">p_{k}(k=1,2, \ldots,|\mathcal{Y}|),</script> 则<script type="math/tex">D</script>的信息嫡定义为</p><script type="math/tex; mode=display">\operatorname{Ent}(D)=-\sum_{k=1}^{|\mathcal{Y}|} p_{k} \log _{2} p_{k}</script><h4 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h4><p>假定离散属性 <script type="math/tex">a</script> 有 <script type="math/tex">V</script> 个可能的取值 <script type="math/tex">\left\{a^{1}, a^{2}, \ldots, a^{V}\right\},</script> 若使用 <script type="math/tex">a</script> 来对样本集 <script type="math/tex">D</script> 进行划分, 则会产生 <script type="math/tex">V</script> 个分支结点, 其中第 <script type="math/tex">v</script> 个分支结点包含了 <script type="math/tex">D</script> 中所有在 属性 <script type="math/tex">a</script> 上取值为 <script type="math/tex">a^{v}</script> 的样本, 记为 <script type="math/tex">D^{v} .</script> 我们可根据式 (4.1) 计算出 <script type="math/tex">D^{v}</script> 的信息嫡, 再考虑到不同的分支结点所包含的样本数不同, 给分支结点赋予权重 <script type="math/tex">\left|D^{v}\right| /|D|,</script> 即样本数越多的分支结点的影响越大, 于是可计算出用属性 <script type="math/tex">a</script> 对样本集 <script type="math/tex">D</script> 进行 划分所获得的“信息增益” </p><script type="math/tex; mode=display">\operatorname{Gain}(D, a)=\operatorname{Ent}(D)-\sum_{v=1}^{V} \frac{\left|D^{v}\right|}{|D|} \operatorname{Ent}\left(D^{v}\right)</script><p>一般而言, 信息增益越大, 则意味着使用属性 <script type="math/tex">a</script> 来进行划分所获得的“纯度提升”越大. 因此, 我们可用信息增益来进行决策树的划分属性选择,  著名的 ID3 决策树学习算法就是以信息增益为准则来选择划分属性</p><p>ID3 算法的优点是方法简单，缺点是对噪声敏感。训练数据如果有少量错误，可能会产生决策树分类错误</p><h4 id="信息增益率"><a href="#信息增益率" class="headerlink" title="信息增益率"></a>信息增益率</h4><script type="math/tex; mode=display">\text {GainRatio}(D, a)=\frac{\operatorname{Gain}(D, a)}{Ent(D)}</script><p>C4.5 在 IID3 的基础上，用信息增益率代替了信息增益，解决了噪声敏感的问题，并且可以对构造树进行剪枝、处理连续数值以及数值缺失等情况，但是由于 C4.5 需要对数据集进行多次扫描，算法效率相对较低</p><h4 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h4><p>基尼指数是经典决策树CART用于分类问题时选择最优特征的指标</p><p>假设有<script type="math/tex">K</script>个类，样本点属于第<script type="math/tex">k</script>类的概率为<script type="math/tex">p_k</script>，则概率分布的基尼指数定义为</p><script type="math/tex; mode=display">G(p)=\sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=1-\sum_{k=1}^{K} p_{k}^{2}</script><p>在信息增益、增益率、基尼指数之外, 人们还设计了许多其他的准则用于决策树划分选择</p><p>然而有实验研究表明这些准则虽然对决策树的尺寸有较大影响, 但对泛化性能的影响很有限</p><h3 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h3><p>决策树的缺点包括对未知的测试数据未必有好的分类、泛化能力，即可能发生过拟合现象，此时可采用剪枝或随机森林</p><p>剪枝是决策树学习算法对付“过拟合”的主要手段</p><p>在决策树学习中, 为了尽可能正确分类训练样本, 结点划分过程将不断重复, 有时会造成决 策树分支过多, 这时就可能因训练样本学得太好了, 以致于把训练集自身 的一些特点当作所有数据都具有的一般性质而导致过拟合</p><h2 id="ID3-决策树代码"><a href="#ID3-决策树代码" class="headerlink" title="ID3 决策树代码"></a>ID3 决策树代码</h2><p>参考 Machine Learning in Action by Peter Harrington</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding = utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecisionTree</span>:</span></span><br><span class="line">    <span class="string">"""ID3 DecisionTree</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.decisionTree = <span class="literal">None</span></span><br><span class="line">        self._X = <span class="literal">None</span></span><br><span class="line">        self._y = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算信息熵</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(self,y)</span>:</span></span><br><span class="line">        lablesCounter = Counter(y)</span><br><span class="line">        shannonEnt = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> lablesCounter.values():</span><br><span class="line">            p = num / len(y)</span><br><span class="line">            shannonEnt += -p * log(p,<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> shannonEnt</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        self._X = X</span><br><span class="line">        self._y = y</span><br><span class="line">        self.decisionTree = self.createTree(self._X,self._y)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">splitDataset</span><span class="params">(self,X,y,d,value)</span>:</span></span><br><span class="line">        features = X[X[:,d]==value]</span><br><span class="line">        labels = y[X[:,d]==value]</span><br><span class="line">        <span class="keyword">return</span> np.concatenate((features[:,:d],features[:,d+<span class="number">1</span>:]),axis=<span class="number">1</span>), labels</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(self,X,y)</span>:</span></span><br><span class="line">        numFeatures = X.shape[<span class="number">1</span>]</span><br><span class="line">        baseEntropy = self.calcShannonEnt(y)</span><br><span class="line">        bestInfoGain, bestFeature = <span class="number">0.0</span>, <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</span><br><span class="line">            <span class="comment"># 创建唯一的分类标签列表</span></span><br><span class="line">            uniqueVals = np.unique(X[:,i])</span><br><span class="line">            newEntropy =<span class="number">0.0</span></span><br><span class="line">            <span class="comment"># 计算每种划分方式的信息熵</span></span><br><span class="line">            <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">                _x, _y = self.splitDataset(X,y,i,value)</span><br><span class="line">                prob = len(_x)/len(X)</span><br><span class="line">                newEntropy += prob * self.calcShannonEnt(_y)</span><br><span class="line">            infoGain = baseEntropy - newEntropy</span><br><span class="line">            <span class="keyword">if</span> infoGain&gt;bestInfoGain:</span><br><span class="line">                bestInfoGain = infoGain</span><br><span class="line">                bestFeature = i</span><br><span class="line">            <span class="keyword">return</span> bestFeature</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(self,y)</span>:</span></span><br><span class="line">        lablesCounter = Counter(y)</span><br><span class="line">        <span class="keyword">return</span> lablesCounter.most_common(<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(self,X,y)</span>:</span></span><br><span class="line">        <span class="comment"># 类别完全相同则停止继续划分</span></span><br><span class="line">        <span class="keyword">if</span> y[y == y[<span class="number">0</span>]].size == y.size :</span><br><span class="line">            <span class="keyword">return</span> y[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 遍历完所有特征时返回出现次数最多的类别</span></span><br><span class="line">        <span class="keyword">if</span> X.shape[<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> self.majorityCnt(y)</span><br><span class="line">        bestFeat = self.chooseBestFeatureToSplit(X,y)</span><br><span class="line">        decisionTree = &#123;bestFeat: &#123;&#125;&#125;</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> np.unique(X[:,bestFeat]):</span><br><span class="line">            decisionTree[bestFeat][value] = self.createTree(*self.splitDataset(X,y,bestFeat, value))</span><br><span class="line">        <span class="keyword">return</span> decisionTree</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    dataSet = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]])</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</span><br><span class="line">    dt = DecisionTree()</span><br><span class="line">    X = dataSet[:, :<span class="number">2</span>]</span><br><span class="line">    X = X.astype(np.int)</span><br><span class="line">    y = dataSet[:,<span class="number">-1</span>]</span><br><span class="line">    dt.fit(X,y)</span><br><span class="line">    print(dt.decisionTree)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://shuwoom.com/?p=1452" target="_blank" rel="noopener">机器学习之-常见决策树算法(ID3、C4.5、CART)</a></p><p><a href="https://www.cnblogs.com/molieren/articles/10664954.html" target="_blank" rel="noopener">决策树</a></p><p><a href="https://zhuanlan.zhihu.com/p/30059442" target="_blank" rel="noopener">决策树(Decision Tree)：通俗易懂之介绍</a></p><p>机器学习-周志华</p><p>Machine Learning in Action by Peter Harrington</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;p&gt;决策树学习采用的是自顶向下的递归方法，其基本思想是以信息熵为度量构造一颗熵值下降最快的树，到叶子节点处，熵值为0&lt;/p&gt;
&lt;p&gt;具有
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="Algorithms" scheme="http://yoursite.com/tags/Algorithms/"/>
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu设置时区</title>
    <link href="http://yoursite.com/2020/10/22/ubuntu%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA/"/>
    <id>http://yoursite.com/2020/10/22/ubuntu%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA/</id>
    <published>2020-10-21T16:12:39.000Z</published>
    <updated>2020-10-21T16:09:11.108Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ubuntu设置时区"><a href="#ubuntu设置时区" class="headerlink" title="ubuntu设置时区"></a>ubuntu设置时区</h1><p>查看现在时区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">benull@37c7dedb7a13:~<span class="comment"># date -R</span></span><br><span class="line">Wed, 21 Oct 2020 23:46:05 +0800</span><br></pre></td></tr></table></figure><p>执行<code>tzselect</code>查看时区(只能查看不能修改）</p><p>遇到tzselect报错如下    </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">benull@37c7dedb7a13:~<span class="comment"># tzselect</span></span><br><span class="line">/usr/bin/tzselect: line 180: /usr/share/zoneinfo/iso3166.tab: No such file or directory</span><br><span class="line">/usr/bin/tzselect: time zone files are not <span class="built_in">set</span> up correctly</span><br></pre></td></tr></table></figure><p>解决方案一：安装tzdata</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install tzdata</span><br></pre></td></tr></table></figure><p>解决方案二：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/bin/tzselect</span><br><span class="line">将</span><br><span class="line"><span class="variable">$&#123;TZDIR=pwd&#125;</span></span><br><span class="line">改为</span><br><span class="line"><span class="variable">$&#123;TZDIR=/usr/share/zoneinfo&#125;</span></span><br></pre></td></tr></table></figure><p>继续执行 tzselect</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">benull@37c7dedb7a13:~# tzselect</span><br><span class="line">Please identify a location so that time zone rules can be set correctly.</span><br><span class="line">Please select a continent, ocean, &quot;coord&quot;, or &quot;TZ&quot;.</span><br><span class="line"> 1) Africa</span><br><span class="line"> 2) Americas</span><br><span class="line"> 3) Antarctica</span><br><span class="line"> 4) Asia</span><br><span class="line"> 5) Atlantic Ocean</span><br><span class="line"> 6) Australia</span><br><span class="line"> 7) Europe</span><br><span class="line"> 8) Indian Ocean</span><br><span class="line"> 9) Pacific Ocean</span><br><span class="line">10) coord - I want to use geographical coordinates.</span><br><span class="line">11) TZ - I want to specify the time zone using the Posix TZ format.</span><br><span class="line">#? 4</span><br><span class="line">Please select a country whose clocks agree with yours.</span><br><span class="line"> 1) Afghanistan  18) Israel    35) Palestine</span><br><span class="line"> 2) Armenia  19) Japan    36) Philippines</span><br><span class="line"> 3) Azerbaijan  20) Jordan    37) Qatar</span><br><span class="line"> 4) Bahrain  21) Kazakhstan    38) Russia</span><br><span class="line"> 5) Bangladesh  22) Korea (North)    39) Saudi Arabia</span><br><span class="line"> 6) Bhutan  23) Korea (South)    40) Singapore</span><br><span class="line"> 7) Brunei  24) Kuwait    41) Sri Lanka</span><br><span class="line"> 8) Cambodia  25) Kyrgyzstan    42) Syria</span><br><span class="line"> 9) China  26) Laos    43) Taiwan</span><br><span class="line">10) Cyprus  27) Lebanon    44) Tajikistan</span><br><span class="line">11) East Timor  28) Macau    45) Thailand</span><br><span class="line">12) Georgia  29) Malaysia    46) Turkmenistan</span><br><span class="line">13) Hong Kong  30) Mongolia    47) United Arab Emirates</span><br><span class="line">14) India  31) Myanmar (Burma)    48) Uzbekistan</span><br><span class="line">15) Indonesia  32) Nepal    49) Vietnam</span><br><span class="line">16) Iran  33) Oman    50) Yemen</span><br><span class="line">17) Iraq  34) Pakistan</span><br><span class="line">#? 9</span><br><span class="line">Please select one of the following time zone regions.</span><br><span class="line">1) Beijing Time</span><br><span class="line">2) Xinjiang Time</span><br><span class="line">#? 1</span><br><span class="line"></span><br><span class="line">The following information has been given:</span><br><span class="line"></span><br><span class="line">China</span><br><span class="line">Beijing Time</span><br><span class="line"></span><br><span class="line">Therefore TZ=&apos;Asia/Shanghai&apos; will be used.</span><br><span class="line">Local time is now:Thu Oct 22 00:02:14 CST 2020.</span><br><span class="line">Universal Time is now:Wed Oct 21 16:02:14 UTC 2020.</span><br><span class="line">Is the above information OK?</span><br><span class="line">1) Yes</span><br><span class="line">2) No</span><br><span class="line">#? 1</span><br><span class="line"></span><br><span class="line">You can make this change permanent for yourself by appending the line</span><br><span class="line">TZ=&apos;Asia/Shanghai&apos;; export TZ</span><br><span class="line">to the file &apos;.profile&apos; in your home directory; then log out and log in again.</span><br><span class="line"></span><br><span class="line">Here is that TZ value again, this time on standard output so that you</span><br><span class="line">can use the /usr/bin/tzselect command in shell scripts:</span><br><span class="line">Asia/Shanghai</span><br></pre></td></tr></table></figure><p>复制文件到 <code>/etc/localtime</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/TonyZhao/p/11169840.html" target="_blank" rel="noopener">Ubuntu设置时区和更新时间</a></p><p><a href="https://my.oschina.net/u/914655/blog/3078043" target="_blank" rel="noopener">ubuntu设置时区</a></p><p><a href="https://blog.csdn.net/mashuai720/article/details/78662607" target="_blank" rel="noopener">ubuntu 时区 修改时间 保存 重启 变化等</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ubuntu设置时区&quot;&gt;&lt;a href=&quot;#ubuntu设置时区&quot; class=&quot;headerlink&quot; title=&quot;ubuntu设置时区&quot;&gt;&lt;/a&gt;ubuntu设置时区&lt;/h1&gt;&lt;p&gt;查看现在时区&lt;/p&gt;
&lt;figure class=&quot;highlight ba
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="Ubuntu" scheme="http://yoursite.com/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>ascii codec can&#39;t encode characters in position</title>
    <link href="http://yoursite.com/2020/10/21/&#39;ascii&#39;%20codec%20can&#39;t%20encode%20characters%20in%20position/"/>
    <id>http://yoursite.com/2020/10/21/&#39;ascii&#39;%20codec%20can&#39;t%20encode%20characters%20in%20position/</id>
    <published>2020-10-21T15:45:32.000Z</published>
    <updated>2020-10-21T15:42:28.769Z</updated>
    
    <content type="html"><![CDATA[<h1 id="‘ascii’-codec-can’t-encode-characters-in-position"><a href="#‘ascii’-codec-can’t-encode-characters-in-position" class="headerlink" title="‘ascii’ codec can’t encode characters in position"></a>‘ascii’ codec can’t encode characters in position</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在ubuntu中运行python3脚本输出到命令行出错</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol><li><p>将<code>LANG</code> 或 <code>LC_ALL</code> 设置为 <code>en_US.utf8</code> 或 <code>zh_CN.utf8</code></p><ul><li>列出当前设置</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">benull@37c7dedb7a13:~<span class="comment"># locale</span></span><br><span class="line">LANG=zh_CN.UTF-8</span><br><span class="line">LANGUAGE=</span><br><span class="line">LC_CTYPE=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_NUMERIC=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_TIME=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_COLLATE=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_MONETARY=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_MESSAGES=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_PAPER=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_NAME=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_ADDRESS=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_TELEPHONE=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_MEASUREMENT=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_IDENTIFICATION=<span class="string">"en_US.UTF-8"</span></span><br><span class="line">LC_ALL=en_US.UTF-8</span><br></pre></td></tr></table></figure><ul><li>列出已安装的语言环境</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">benull@37c7dedb7a13:~<span class="comment"># locale -a</span></span><br><span class="line">C</span><br><span class="line">C.UTF-8</span><br><span class="line">en_US.utf8</span><br><span class="line">POSIX</span><br><span class="line">zh_CN.utf8</span><br></pre></td></tr></table></figure></li><li><p>如果不存在上述的 <code>locale</code>，先用 <code>locale-gen</code> 生成</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apt-get install locales</span><br><span class="line">locale-gen <span class="string">'zh_CN.UTF-8'</span></span><br><span class="line">update-locale LC_ALL=<span class="string">"zh_CN.UTF-8"</span></span><br></pre></td></tr></table></figure><ol><li>将<code>export LC_ALL=zh_CN.UTF-8&quot;</code> 加到的<code>~/.bashrc</code></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.v2ex.com/amp/t/422301" target="_blank" rel="noopener">关于’ascii’ codec can’t encode characters in position 的问题</a></p><p><a href="https://blog.csdn.net/wangzhenling/article/details/104781048" target="_blank" rel="noopener">ubuntu locales 设置中文</a></p><p><a href="https://help.ubuntu.com/community/Locale" target="_blank" rel="noopener">Locale</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;‘ascii’-codec-can’t-encode-characters-in-position&quot;&gt;&lt;a href=&quot;#‘ascii’-codec-can’t-encode-characters-in-position&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>k近邻算法(KNN)</title>
    <link href="http://yoursite.com/2020/10/20/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2020/10/20/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/</id>
    <published>2020-10-19T16:25:29.000Z</published>
    <updated>2020-10-19T17:09:06.638Z</updated>
    
    <content type="html"><![CDATA[<h1 id="k近邻算法"><a href="#k近邻算法" class="headerlink" title="k近邻算法"></a>k近邻算法</h1><p>k近邻算法( k-Nearest Neighbor)是一种监督学习<br>优点:精度高、对异常值不敏感、无数据输入假定<br>缺点:计算复杂度高、空间复杂度高</p><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>给定测试样本, 基于某种距离度量找出训练集中与其最靠近的 <script type="math/tex">k</script> 个训练样本, 然后基于这 <script type="math/tex">k</script> 个邻居的信息来进行预测</p><p>一般流程包括：</p><ol><li>计算已知类别数据集中的点与当前点之间的距离</li><li>按照距离递增次序排序</li><li>选取与当前点距离最小的k个点</li><li>确定前k个点所在类别的出现频率</li><li>返回前k个点出现频率最高的类别作为当前点的预测分类</li></ol><p>分类任务中可选择这 <script type="math/tex">k</script> 个样本中出现最多的类别标记作为预测结果</p><p>回归任务中可将这 <script type="math/tex">k</script> 个样本的实值输出标记的平均值作为预测结果</p><h2 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h2><p>当 <script type="math/tex">k</script>取不同值时, 分类结果会有显著不同</p><p>K值过小：特征空间被划分为更多子空间，整体模型变复杂，预测结果会对近邻点十分敏感，预测就会出错容易发生过拟合<br>K值过大：近邻误差会偏大，距离较远的点也会同样对预测结果产生影响，使得预测结果产生较大偏差，此时模型容易发生欠拟合</p><h2 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h2><p>若采用不同的距离计算方式也会导致分类结果有显著不同</p><p>对函数 <script type="math/tex">\operatorname{dist}(\cdot, \cdot)</script>，若它是一个距离度量，则需满足一些基本性质</p><script type="math/tex; mode=display">非负性:\operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \geqslant 0</script><script type="math/tex; mode=display">\text { 同一性: } \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=0 \text { 当且仅当 } \boldsymbol{x}_{i}=\boldsymbol{x}_{j}</script><script type="math/tex; mode=display">\begin{aligned}&\text { 对称性: } \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\operatorname{dist}\left(\boldsymbol{x}_{j}, \boldsymbol{x}_{i}\right)\\&\text { 直递性: } \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \leqslant \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{k}\right)+\operatorname{dist}\left(\boldsymbol{x}_{k}, \boldsymbol{x}_{j}\right)\end{aligned}</script><p>给定样本 <script type="math/tex">\boldsymbol{x}_{i}=\left(x_{i 1} ; x_{i 2} ; \ldots ; x_{i n}\right)</script> 与 <script type="math/tex">\boldsymbol{x}_{j}=\left(x_{j 1} ; x_{j 2} ; \ldots ; x_{j n}\right)</script><br>最常用的是闵可夫斯基距离(Minkowski distance）</p><script type="math/tex; mode=display">\operatorname{dist}_{\mathrm{mk}}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\left(\sum_{u=1}^{n}\left|x_{i u}-x_{j u}\right|^{p}\right)^{\frac{1}{p}}</script><p>当 <script type="math/tex">p=2</script> 时, 闵可夫斯基距离即欧氏距离 (Euclidean distance)</p><p>欧几里得空间中两点间直线距离、真实距离或者向量的自然长度</p><script type="math/tex; mode=display">\operatorname{dist}_{\mathrm{ed}}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|_{2}=\sqrt{\sum_{u=1}^{n}\left|x_{i u}-x_{j u}\right|^{2}}</script><p>当 <script type="math/tex">p=1</script> 时, 闵可夫斯基距离即曼哈顿距离(Manhattan distance)</p><p>在欧几里德空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和，也称街区距离</p><script type="math/tex; mode=display">\operatorname{dist}_{\operatorname{man}}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right)=\left\|\boldsymbol{x}_{i}-\boldsymbol{x}_{j}\right\|_{1}=\sum_{u=1}^{n}\left|x_{i u}-x_{j u}\right|</script><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>FROM <a href="https://coding.imooc.com/class/169.html" target="_blank" rel="noopener">IMOOC机器学习</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNNClassifier</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k)</span>:</span></span><br><span class="line">        <span class="string">"""初始化kNN分类器"""</span></span><br><span class="line">        <span class="keyword">assert</span> k &gt;= <span class="number">1</span>, <span class="string">"k must be valid"</span></span><br><span class="line">        self.k = k</span><br><span class="line">        self._X_train = <span class="literal">None</span></span><br><span class="line">        self._y_train = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X_train, y_train)</span>:</span></span><br><span class="line">        <span class="string">"""根据训练数据集X_train和y_train训练kNN分类器"""</span></span><br><span class="line">        <span class="keyword">assert</span> X_train.shape[<span class="number">0</span>] == y_train.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">"the size of X_train must be equal to the size of y_train"</span></span><br><span class="line">        <span class="keyword">assert</span> self.k &lt;= X_train.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">"the size of X_train must be at least k."</span></span><br><span class="line"></span><br><span class="line">        self._X_train = X_train</span><br><span class="line">        self._y_train = y_train</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X_predict)</span>:</span></span><br><span class="line">        <span class="string">"""给定待预测数据集X_predict，返回表示X_predict的结果向量"""</span></span><br><span class="line">        <span class="keyword">assert</span> self._X_train <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self._y_train <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, \</span><br><span class="line">                <span class="string">"must fit before predict!"</span></span><br><span class="line">        <span class="keyword">assert</span> X_predict.shape[<span class="number">1</span>] == self._X_train.shape[<span class="number">1</span>], \</span><br><span class="line">                <span class="string">"the feature number of X_predict must be equal to X_train"</span></span><br><span class="line"></span><br><span class="line">        y_predict = [self._predict(x) <span class="keyword">for</span> x <span class="keyword">in</span> X_predict]</span><br><span class="line">        <span class="keyword">return</span> np.array(y_predict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_predict</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""给定单个待预测数据x，返回x的预测结果值"""</span></span><br><span class="line">        <span class="keyword">assert</span> x.shape[<span class="number">0</span>] == self._X_train.shape[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">"the feature number of x must be equal to X_train"</span></span><br><span class="line"></span><br><span class="line">        distances = [sqrt(np.sum((x_train - x) ** <span class="number">2</span>))</span><br><span class="line">                     <span class="keyword">for</span> x_train <span class="keyword">in</span> self._X_train]</span><br><span class="line">        nearest = np.argsort(distances)</span><br><span class="line"></span><br><span class="line">        topK_y = [self._y_train[i] <span class="keyword">for</span> i <span class="keyword">in</span> nearest[:self.k]]</span><br><span class="line">        votes = Counter(topK_y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> votes.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, X_test, y_test)</span>:</span></span><br><span class="line">        <span class="string">"""根据测试数据集 X_test 和 y_test 确定当前模型的准确度"""</span></span><br><span class="line"></span><br><span class="line">        y_predict = self.predict(X_test)</span><br><span class="line">        <span class="keyword">return</span> self.accuracy_score(y_test, y_predict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"KNN(k=%d)"</span> % self.k</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">        <span class="string">"""计算y_true和y_predict之间的准确率"""</span></span><br><span class="line">        <span class="keyword">assert</span> len(y_true) == len(y_predict), \</span><br><span class="line">            <span class="string">"the size of y_true must be equal to the size of y_predict"</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> np.sum(y_true == y_predict) / len(y_true)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/pxhdky/article/details/85067808" target="_blank" rel="noopener">LP距离、欧式距离、曼哈顿距离、切比雪夫距离</a></p><p><a href="https://blog.csdn.net/hajk2017/article/details/82862788" target="_blank" rel="noopener">什么是KNN算法？</a></p><p><a href="https://coding.imooc.com/class/169.html" target="_blank" rel="noopener">IMOOC机器学习</a></p><p>机器学习-周志华</p><p>Machine Learning in Action by Peter Harrington</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;k近邻算法&quot;&gt;&lt;a href=&quot;#k近邻算法&quot; class=&quot;headerlink&quot; title=&quot;k近邻算法&quot;&gt;&lt;/a&gt;k近邻算法&lt;/h1&gt;&lt;p&gt;k近邻算法( k-Nearest Neighbor)是一种监督学习&lt;br&gt;优点:精度高、对异常值不敏感、无数据输入假
      
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/categories/AI/"/>
    
    
      <category term="Algorithms" scheme="http://yoursite.com/tags/Algorithms/"/>
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
      <category term="KNN" scheme="http://yoursite.com/tags/KNN/"/>
    
  </entry>
  
  <entry>
    <title>Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition</title>
    <link href="http://yoursite.com/2020/10/13/%E5%9F%BA%E4%BA%8E%E9%AA%A8%E6%9E%B6%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E7%9A%84%E7%A9%BA%E9%97%B4%E6%AE%8B%E5%B7%AE%E5%B1%82%E5%92%8C%E5%AF%86%E9%9B%86%E8%BF%9E%E6%8E%A5%E5%9D%97%E5%A2%9E%E5%BC%BA%E7%9A%84%E6%97%B6%E7%A9%BA%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2020/10/13/%E5%9F%BA%E4%BA%8E%E9%AA%A8%E6%9E%B6%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB%E7%9A%84%E7%A9%BA%E9%97%B4%E6%AE%8B%E5%B7%AE%E5%B1%82%E5%92%8C%E5%AF%86%E9%9B%86%E8%BF%9E%E6%8E%A5%E5%9D%97%E5%A2%9E%E5%BC%BA%E7%9A%84%E6%97%B6%E7%A9%BA%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/</id>
    <published>2020-10-13T11:23:35.000Z</published>
    <updated>2020-11-04T16:25:02.205Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spatial-Residual-Layer-and-Dense-Connection-Block-Enhanced-Spatial-Temporal-Graph-Convolutional-Network-for-Skeleton-Based-Action-Recognition"><a href="#Spatial-Residual-Layer-and-Dense-Connection-Block-Enhanced-Spatial-Temporal-Graph-Convolutional-Network-for-Skeleton-Based-Action-Recognition" class="headerlink" title="Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition"></a>Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition</h1><h2 id="基于骨架动作识别的空间残差层和密集连接块增强的时空图卷积网络"><a href="#基于骨架动作识别的空间残差层和密集连接块增强的时空图卷积网络" class="headerlink" title="基于骨架动作识别的空间残差层和密集连接块增强的时空图卷积网络"></a>基于骨架动作识别的空间残差层和密集连接块增强的时空图卷积网络</h2><h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><div class="table-container"><table><thead><tr><th>作者单位</th><th>会议</th><th>论文地址</th><th>代码</th></tr></thead><tbody><tr><td>江南大学</td><td>ICCV 2019</td><td><a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/SGRL/Wu_Spatial_Residual_Layer_and_Dense_Connection_Block_Enhanced_Spatial_Temporal_ICCVW_2019_paper.pdf" target="_blank" rel="noopener">论文地址</a></td><td>暂无</td></tr></tbody></table></div><h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><p>引入了空间残差层来捕获和融合时空特征<br>在先前的工作中，时空层包括空间图卷积和时间卷积。但是不同卷积的序列叠加会混合不同域的信息，从而导致识别不准确。通过引入跨域空间残差卷积，可以增强时空信息</p><p>此外，提出了一个密集连接块来提取全局信息</p><p>它由多个空间残差层组成。在这些层中，可以通过密集连接来传递信息。</p><p>结合上面提到的两个组件来创建了一个时空图卷积网络(ST-GCN),称为SDGCN</p><p><img src="https://pic3.zhimg.com/80/v2-d226e3e1c29a4dcce46c3bb947bd51ee_1440w.jpg" alt="img"></p><blockquote><p>图1.该方法将2D空间卷积与1D时间卷积集成在一起，用于时空特征表示，用于基于骨骼的动作识别。 蓝色方块代表空间图卷积，黄色代表时间卷积。</p></blockquote><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>主要工作：空间残差层和密集连接块增强的时空图卷积网络</p><h3 id="空间残差层Spatial-Residual-Layer-SRL"><a href="#空间残差层Spatial-Residual-Layer-SRL" class="headerlink" title="空间残差层Spatial Residual Layer (SRL)"></a>空间残差层Spatial Residual Layer (SRL)</h3><p>​    ResNet 首先通过引入残差结构来提出残差连接的概念，其中输入节点信息通过恒等映射传递。残差映射的想法是删除相同的主要部分，从而突出显示较小的更改。通过引入残差映射，整个结构对输出的变化更加敏感。残差层可以看作是一个放大器，经过合理的设置，敏感信息会被放大，因此残差连接只需要关心它需要学习的内容即可。</p><p><img src="https://pic3.zhimg.com/80/v2-e3a662c73a31025e27f3dd0e1607462d_1440w.jpg" alt="img"></p><blockquote><p>图2.空间残差ST-GCN层。 下部是ST-GCN层，由空间图卷积和时间卷积组成，上部是空间图卷积。 就像在ResNet中一样，残差连接的输入与ST-GCN层相同，然后将从残差连接获得的输出添加到ST-GCN层的输出中，相加的结果是最终的输出。</p></blockquote><p>​    这里的空间残差连接是跨域的。时空融合网络由空间图卷积分支和时空卷积分支组成。恒等映射是图中的下流。与原始的ResNet不同，此处的恒等映射由图卷积组成，该图卷积也可以视为特殊的双流结构，其中一个流学习静态特征，而另一个流学习时空特征。通过2D空间图卷积，可以提取静态空间特征。由于残差连接，残差图将注意静态空间信息。原始层只需要重视时空信息。这种设计使GCN可以更有效地从视频中学习重要信息。</p><h3 id="密集连接块Dense-Connection-Block-DCB"><a href="#密集连接块Dense-Connection-Block-DCB" class="headerlink" title="密集连接块Dense Connection Block (DCB)"></a>密集连接块Dense Connection Block (DCB)</h3><p>它的结构非常简单，由几个密集的连接块组成。在每个块中，每个图层的特征图都与相同尺度的所有先前特征连接在一起。通过引入密集连接，将重用每一层的特征。一方面，使用少量的计算，可以获得更丰富的特征图。另一方面，重用特征更强大，因此减少了不同层之间的依赖性。</p><p><img src="https://pic2.zhimg.com/80/v2-e536267e21d4c87281fd0a36521bc12a_1440w.jpg" alt="img"></p><blockquote><p>图3.每个密集的连接块都包含几个空间残差层。 在这里，除了第一层或最后一层，每层输入特征的大小与上一层的输出大小完全相同。 </p></blockquote><p>​    在每个密集连接块中，每一层都已连接到所有后续层。 <strong>在通道中将它们全部串联</strong>在一起。 这样，可以在以后的层中重用先前层所提取的大多数信息。 就像DenseNet一样，此块允许整个网络充分利用全局信息。 最重要的是，从特征的角度来看，通过特征重用和旁路设置，可以大大减少网络参数的数量，并在一定程度上缓解了梯度消失的问题。 另一方面，每一层的输入不仅包括前一层的输出，而且还包括其他先前的层。 这也提高了网络的健壮性。</p><h3 id="总体结构"><a href="#总体结构" class="headerlink" title="总体结构"></a>总体结构</h3><p>在这里，将空间残差层和密集连接块组合在一起，以形成最终的体系结构，称为SDGCN。注意，几个空间残差层构成一个块。引入密集连接来连接每个块中的这些层。整个网络结构由3个密集连接块组成。在每个块中，通道大小的设置可以充分利用密集连接。采用原始ST-GCN的设置，这确保了所提出的方法可以应用于常用的ST-GCN结构。</p><p><img src="https://pic2.zhimg.com/80/v2-680b3f6df425460d7b2562e65b59d784_1440w.jpg" alt="img"></p><blockquote><p>图4.左：基于DCB1的SDGCN。 遵循标准的ST-GCN模型来设计模型。右：基于DCB2的SDGCN。 与左图相比，为了充分探讨密集连接的作用，引入了更多的层和密集连接。空心圆表示SRL。</p></blockquote><h2 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h2><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p><img src="https://pic2.zhimg.com/80/v2-8ef7b0719590ec00a1b813e71ea54f11_1440w.jpg" alt="img"></p><blockquote><p>表1.在Kinetics数据集上的消融实验。 SRL表示空间残差层，DCB表示密集连接块(DCB1和DCB2)，如图4所示。 报告了在Kinetics数据集上的TOP-1和TOP-5准确率。</p><p>表2.在NTU-RGB+D数据集的消融实验。 我们报告交叉对象和交叉视图数据上的准确性。 其他符号与Tab相同。 只上报TOP-1准确率。</p></blockquote><p>对Kinetics和NTU-RGB + D进行详细的实验比较</p><h4 id="空间残差层"><a href="#空间残差层" class="headerlink" title="空间残差层"></a>空间残差层</h4><p>首先以STGCN 为基准，探索跨域空间残差层的有效性</p><p>与原始结构相比，对于由空间图卷积运算和时间卷积串联组成的每个时空结构，我们向原始网络引入空间残差连接，简称为SRL，并保留其他条件不变</p><p>发现与基线方法相比，带有SRL的ST-GCN表现出明显的改进</p><p>在Kinetics上，性能提高了2.61％</p><p>对于NTU-RGB + D，Cross-Subject和Cross-View的性能分别提高了1.75％和2.76％</p><h4 id="密集连接块"><a href="#密集连接块" class="headerlink" title="密集连接块"></a>密集连接块</h4><p>DCB1基于原始结构，包含10层。为了演示密集连接的作用，设计了DCB2，它包含12层</p><p>具有DCB1的ST-GCN的性能提高了1.51％，具有DCB2的ST-GCN的性能提高了2.48％</p><p>显然，密集的连接为我们的网络做出了很大的贡献，但是，随着密集连接的增加，网络参数的数量迅速增加。此外，盲目的累积网络复杂性可能导致某些数据集的模型过度拟合。</p><h3 id="结果比较"><a href="#结果比较" class="headerlink" title="结果比较"></a>结果比较</h3><p>为了进行全面的比较，选择将我们的方法与两个重要的基线相比：ST-GCN 和2s-AGCN 。第一个基准是基于骨骼的动作识别方面的开创性工作，而2s-AGCN是最新的最佳方法。将SRL和DCB合并在一起以报告最终结果。最终模型表示为SDGCN。</p><p>与基于ST-GCN的方法相比，在Kinetics上的准确性提高到34.06％，在Cross-Subject和Cross-View测试中分别提高到84.04％和91.43％。</p><p>当2s-AGCN作为基准时，在Kinetics上，所提出的方法达到了37.35％的精度。在NTU-RGB + D上，Cross-Subject和Cross-View数据的准确度分别为89.58％和95.74％</p><p><img src="https://pic2.zhimg.com/80/v2-4a022227b16f1873c12a12c5a722e186_1440w.jpg" alt="img"></p><blockquote><p>表3 与目前最先进的方法在Kinetics数据集上的比较</p></blockquote><p><img src="https://pic1.zhimg.com/80/v2-86a0945703f3e4cf63505c7d98460068_1440w.jpg" alt="img"></p><blockquote><p>表4.在NTURGB+D上与现有方法的比较</p></blockquote><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>​    提出了一个统一的时空图卷积网络框架，称为SDGCN，以提高基于骨架的动作识别的性能。通过引入跨域空间图残差层和密集连接块，充分利用了时空信息，提高了时空信息处理的效率。可以很容易地将其合并到主流的时空图网络中。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Spatial-Residual-Layer-and-Dense-Connection-Block-Enhanced-Spatial-Temporal-Graph-Convolutional-Network-for-Skeleton-Based-Action-Re
      
    
    </summary>
    
    
      <category term="Paper" scheme="http://yoursite.com/categories/Paper/"/>
    
    
      <category term="Paper" scheme="http://yoursite.com/tags/Paper/"/>
    
      <category term="ActionRecognition" scheme="http://yoursite.com/tags/ActionRecognition/"/>
    
  </entry>
  
  <entry>
    <title>PyQt5 画图板</title>
    <link href="http://yoursite.com/2020/09/29/PyQt5%E7%94%BB%E5%9B%BE%E6%9D%BF/"/>
    <id>http://yoursite.com/2020/09/29/PyQt5%E7%94%BB%E5%9B%BE%E6%9D%BF/</id>
    <published>2020-09-29T12:15:32.000Z</published>
    <updated>2020-11-04T16:26:18.070Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PyQt5-画图板"><a href="#PyQt5-画图板" class="headerlink" title="PyQt5 画图板"></a>PyQt5 画图板</h1><h2 id="主要技术"><a href="#主要技术" class="headerlink" title="主要技术"></a>主要技术</h2><ul><li>PyQt5</li><li>qtDesigner</li><li>openCV</li></ul><h2 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h2><ul><li>绘画<ul><li>画笔</li><li>油漆桶</li><li>直线</li><li>矩形</li><li>椭圆</li><li>橡皮擦</li></ul></li><li>图片处理<ul><li>旋转、翻转</li><li>亮度、饱和度、对比度、色调调节</li><li>灰度化</li><li>二值化</li><li>反相（反色）</li><li>浮雕</li><li>边缘检测</li><li>模糊</li><li>锐化</li></ul></li></ul><h2 id="详细代码"><a href="#详细代码" class="headerlink" title="详细代码"></a>详细代码</h2><p><a href="https://github.com/BENULL/Paint" target="_blank" rel="noopener">github仓库</a></p><h2 id="实现过程遇到的问题"><a href="#实现过程遇到的问题" class="headerlink" title="实现过程遇到的问题"></a>实现过程遇到的问题</h2><h3 id="在pycharm上使用qtDesigner"><a href="#在pycharm上使用qtDesigner" class="headerlink" title="在pycharm上使用qtDesigner"></a>在pycharm上使用qtDesigner</h3><p>配置qtDesigner</p><p>配置UIC</p><p>参考 <a href="https://blog.csdn.net/u013667527/article/details/97657621" target="_blank" rel="noopener">Mac下pycharm+qtdesigner环境搭建</a></p><h3 id="绘图时图像不能留存或重影问题"><a href="#绘图时图像不能留存或重影问题" class="headerlink" title="绘图时图像不能留存或重影问题"></a>绘图时图像不能留存或重影问题</h3><p>采取双缓冲绘图方法</p><p>我们再添加一个辅助画布，如果正在绘图，也就是鼠标按键还没有释放的时候，就在这个辅助画布上绘图，只有当鼠标按键释放的时候，才在真正的画布上绘图</p><p>参考<a href="http://shouce.jb51.net/qt-beginning/22.html" target="_blank" rel="noopener">2D绘图（八）双缓冲绘图</a></p><h3 id="油漆桶Flood-Fill算法问题"><a href="#油漆桶Flood-Fill算法问题" class="headerlink" title="油漆桶Flood Fill算法问题"></a>油漆桶Flood Fill算法问题</h3><p>泛洪算法—Flood Fill，用于确定连接到多维数组中给定节点的区域。</p><p>基本原理就是从一个像素点出发，以此向周边的像素点扩充着色，直到图形的边界。</p><p>实现方法包括传统递归方式dfs、bfs和描绘线算法(Scanline Fill)等</p><p>在QImage上实现效率很低，因为getPixel操作很慢，可以进一步优化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPixel</span><span class="params">(x,y,pixels,w)</span>:</span></span><br><span class="line">    i = (x + (y * w)) * <span class="number">4</span></span><br><span class="line">    <span class="keyword">return</span> pixels[i:i + <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 油漆桶</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">floodFill</span><span class="params">(image,pos)</span>:</span></span><br><span class="line">    fillPositions = []</span><br><span class="line">    w, h = image.width(), image.height()</span><br><span class="line">    pixels = image.bits().asstring(w * h * <span class="number">4</span>)</span><br><span class="line">    targetColor = getPixel(pos.x(), pos.y(), pixels, w)</span><br><span class="line"></span><br><span class="line">    haveSeen = set()</span><br><span class="line">    queue = [(pos.x(), pos.y())]</span><br><span class="line">    <span class="keyword">while</span> queue:</span><br><span class="line">        x, y = queue.pop()</span><br><span class="line">        <span class="keyword">if</span> getPixel(x, y,pixels,w) == targetColor:</span><br><span class="line">            fillPositions.append((x,y))</span><br><span class="line">            queue.extend(getCardinalPoints(haveSeen, (x, y),w,h))</span><br><span class="line">    <span class="keyword">return</span> fillPositions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCardinalPoints</span><span class="params">(haveSeen, centerPos,w,h)</span>:</span></span><br><span class="line">    points = []</span><br><span class="line">    cx, cy = centerPos</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> [(<span class="number">1</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">-1</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">-1</span>)]:</span><br><span class="line">        xx, yy = cx + x, cy + y</span><br><span class="line">        <span class="keyword">if</span> (xx &gt;= <span class="number">0</span> <span class="keyword">and</span> xx &lt; w <span class="keyword">and</span> yy &gt;= <span class="number">0</span> <span class="keyword">and</span> yy &lt; h <span class="keyword">and</span> (xx, yy) <span class="keyword">not</span> <span class="keyword">in</span> haveSeen):</span><br><span class="line">            points.append((xx, yy))</span><br><span class="line">            haveSeen.add((xx, yy))</span><br><span class="line">    <span class="keyword">return</span> points</span><br></pre></td></tr></table></figure><p>参考<a href="https://www.learnpyqt.com/blog/implementing-qpainter-flood-fill-pyqt5pyside/" target="_blank" rel="noopener">Implementing QPainter flood fill in PyQt5/PySide</a></p><p><a href="https://www.pianshen.com/article/172962944/" target="_blank" rel="noopener">图像分割经典算法—《泛洪算法》（Flood Fill)</a></p><h3 id="Mac上pyqt5-与-cv库冲突问题"><a href="#Mac上pyqt5-与-cv库冲突问题" class="headerlink" title="Mac上pyqt5 与 cv库冲突问题"></a>Mac上pyqt5 与 cv库冲突问题</h3><p>问题<code>You might be loading **two sets of Qt binaries** into the same process</code></p><p>删除原有的opencv       </p><p><code>pip3 uninstall opencv-python</code></p><p>安装opencv–headless版本</p><p><code>pip3 install opencv-contrib-python-headless</code></p><p>参考<a href="https://blog.csdn.net/qq_43444349/article/details/106602543" target="_blank" rel="noopener">Mac下使用opencv与pyqt发生冲突</a></p><h3 id="pyqt-QImage-与opencv-MAT格式转化问题"><a href="#pyqt-QImage-与opencv-MAT格式转化问题" class="headerlink" title="pyqt QImage 与opencv MAT格式转化问题"></a>pyqt QImage 与opencv MAT格式转化问题</h3><p>在使用opencv过程中需要传入QImage对象进行处理</p><p>QImage转化成opencv下的 MAT(numpy ndarray) 对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CvMatToQImage</span><span class="params">(cvMat)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(cvMat.shape) == <span class="number">2</span>:</span><br><span class="line">        rows, columns = cvMat.shape</span><br><span class="line">        bytesPerLine = columns</span><br><span class="line">        <span class="keyword">return</span> QImage(cvMat.data, columns, rows, bytesPerLine, QImage.Format_Indexed8)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        rows, columns, channels = cvMat.shape</span><br><span class="line">        bytesPerLine = channels * columns</span><br><span class="line">        <span class="keyword">return</span> QImage(cvMat.data, columns, rows, bytesPerLine, QImage.Format_RGBA8888)</span><br></pre></td></tr></table></figure><p>MAT(numpy ndarray) 转QImage</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">QImageToCvMat</span><span class="params">(incomingImage)</span>:</span></span><br><span class="line">    incomingImage = incomingImage.convertToFormat(QImage.Format_RGBA8888)</span><br><span class="line">    width = incomingImage.width()</span><br><span class="line">    height = incomingImage.height()</span><br><span class="line">    ptr = incomingImage.bits()</span><br><span class="line">    ptr.setsize(height * width * <span class="number">4</span>)</span><br><span class="line">    arr = np.frombuffer(ptr, np.uint8).reshape((height, width, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure><p>参考<a href="https://blog.csdn.net/lch551218/article/details/104882183/" target="_blank" rel="noopener">Python 中如何将 Pyqt5 下的 QImage 对象转换成 PIL image 或 opencv MAT (numpy ndarray) 对象</a></p><h2 id="效果预览"><a href="#效果预览" class="headerlink" title="效果预览"></a>效果预览</h2><h3 id="绘画"><a href="#绘画" class="headerlink" title="绘画"></a>绘画</h3><p><img src="https://b1.sbimg.org/file/chevereto-jia/2020/09/30/GZ6Oo.png" alt></p><h3 id="油漆桶效果"><a href="#油漆桶效果" class="headerlink" title="油漆桶效果"></a>油漆桶效果</h3><p><img src="https://sbimg.cn/images/2020/09/30/GZpxa.png" alt></p><h3 id="图像处理部分展示"><a href="#图像处理部分展示" class="headerlink" title="图像处理部分展示"></a>图像处理部分展示</h3><h3 id="原图"><a href="#原图" class="headerlink" title="原图"></a>原图</h3><p><img src="https://b1.sbimg.org/file/chevereto-jia/2020/09/30/GZGDl.png" alt></p><h3 id="亮度调节"><a href="#亮度调节" class="headerlink" title="亮度调节"></a>亮度调节</h3><p><img src="https://b1.sbimg.org/file/chevereto-jia/2020/09/30/GZ3zw.png" alt></p><h3 id="色调调节"><a href="#色调调节" class="headerlink" title="色调调节"></a>色调调节</h3><p><img src="https://sbimg.cn/images/2020/09/30/GZmuM.png" alt></p><h3 id="反相"><a href="#反相" class="headerlink" title="反相"></a>反相</h3><p><img src="https://b1.sbimg.org/file/chevereto-jia/2020/09/30/GZoGT.png" alt></p><h3 id="灰度化"><a href="#灰度化" class="headerlink" title="灰度化"></a>灰度化</h3><p><img src="https://sbimg.cn/images/2020/09/30/GZ0mR.png" alt></p><h3 id="二值化"><a href="#二值化" class="headerlink" title="二值化"></a>二值化</h3><p><img src="https://sbimg.cn/images/2020/09/30/GZ2dI.png" alt></p><h3 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h3><p><img src="https://sbimg.cn/images/2020/09/30/GZCZK.png" alt></p><h2 id="部分参考"><a href="#部分参考" class="headerlink" title="部分参考"></a>部分参考</h2><p><a href="https://www.cnblogs.com/lfri/p/10599420.html" target="_blank" rel="noopener">https://www.cnblogs.com/lfri/p/10599420.html</a><a href="https://blog.csdn.net/qq_43444349/article/details/106602543" target="_blank" rel="noopener">https://blog.csdn.net/qq_43444349/article/details/106602543</a><br><a href="https://www.pianshen.com/article/172962944/" target="_blank" rel="noopener">https://www.pianshen.com/article/172962944/</a><br><a href="https://blog.csdn.net/lzwarhang/article/details/93209166" target="_blank" rel="noopener">https://blog.csdn.net/lzwarhang/article/details/93209166</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PyQt5-画图板&quot;&gt;&lt;a href=&quot;#PyQt5-画图板&quot; class=&quot;headerlink&quot; title=&quot;PyQt5 画图板&quot;&gt;&lt;/a&gt;PyQt5 画图板&lt;/h1&gt;&lt;h2 id=&quot;主要技术&quot;&gt;&lt;a href=&quot;#主要技术&quot; class=&quot;headerli
      
    
    </summary>
    
    
      <category term="Project" scheme="http://yoursite.com/categories/Project/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Project" scheme="http://yoursite.com/tags/Project/"/>
    
      <category term="Qt" scheme="http://yoursite.com/tags/Qt/"/>
    
  </entry>
  
</feed>
